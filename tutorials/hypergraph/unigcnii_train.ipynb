{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a hypergraph neural network using UniGCNII layers\n",
    "\n",
    "This tutorial consists of three main steps:\n",
    "1. Loading the CiCitationCora dataset and lifting it to the hypergraph domain.\n",
    "2. Defining a hypergraph neural network (HGNN) which utlilizes the UniGCNII layer, and\n",
    "3. Training the obtained neural network on the training data and evaluating it on test data.\n",
    "\n",
    "First, we import the neccessary packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from topomodelx.nn.hypergraph.unigcnii_layer import UniGCNIILayer\n",
    "from topomodelx.nn.hypergraph.unigcnii import UniGCNII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPUs are available, we want to make use of them, otherwise the model is run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "We are using the Cora co-citation dataset. Here, the nodes represent documents and the edges in the graph represent documents which are co-cited. It is possible to compute this graph from the citation network directly. However, this is computationally very expensive. Instead, we load the dataset directly as it is available to download.\n",
    "\n",
    "The task here is to classify each node and assign one of 7 possible classes to it. The dataset is a standard benchmark used in HGNN literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-13 14:18:50--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/features.pickle\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/features.pickle [following]\n",
      "--2023-07-13 14:18:51--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/features.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 404937 (395K) [application/octet-stream]\n",
      "Saving to: ‘features.pickle’\n",
      "\n",
      "features.pickle     100%[===================>] 395.45K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-07-13 14:18:51 (3.93 MB/s) - ‘features.pickle’ saved [404937/404937]\n",
      "\n",
      "--2023-07-13 14:18:51--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/hypergraph.pickle\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/hypergraph.pickle [following]\n",
      "--2023-07-13 14:18:52--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/hypergraph.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 101905 (100K) [application/octet-stream]\n",
      "Saving to: ‘hypergraph.pickle’\n",
      "\n",
      "hypergraph.pickle   100%[===================>]  99.52K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2023-07-13 14:18:52 (4.37 MB/s) - ‘hypergraph.pickle’ saved [101905/101905]\n",
      "\n",
      "--2023-07-13 14:18:52--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/labels.pickle\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/labels.pickle [following]\n",
      "--2023-07-13 14:18:53--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/labels.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5436 (5.3K) [application/octet-stream]\n",
      "Saving to: ‘labels.pickle’\n",
      "\n",
      "labels.pickle       100%[===================>]   5.31K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-07-13 14:18:53 (18.8 MB/s) - ‘labels.pickle’ saved [5436/5436]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/features.pickle\n",
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/hypergraph.pickle\n",
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/labels.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-13 14:18:53--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/splits/1.pickle\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/splits/1.pickle [following]\n",
      "--2023-07-13 14:18:54--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/splits/1.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 51582 (50K) [application/octet-stream]\n",
      "Saving to: ‘1.pickle’\n",
      "\n",
      "1.pickle            100%[===================>]  50.37K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2023-07-13 14:18:54 (4.51 MB/s) - ‘1.pickle’ saved [51582/51582]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/splits/1.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14655/121206761.py:2: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  features = pickle.load(handle).todense()\n"
     ]
    }
   ],
   "source": [
    "with open(\"features.pickle\", \"rb\") as handle:\n",
    "    features = pickle.load(handle).todense()\n",
    "\n",
    "with open(\"hypergraph.pickle\", \"rb\") as handle:\n",
    "    hypergraph = pickle.load(handle)\n",
    "\n",
    "with open(\"labels.pickle\", \"rb\") as handle:\n",
    "    labels = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the input and output features to pytorch\n",
    "x_0 = sp.csr_matrix(np.array(features), dtype=np.float32)\n",
    "x_0 = torch.FloatTensor(np.array(x_0.todense()))\n",
    "x_0 = x_0.to(device)\n",
    "\n",
    "y = torch.LongTensor(np.array(labels))\n",
    "y = y.to(device)\n",
    "\n",
    "# construct the incidence matrix\n",
    "h = np.zeros((x_0.shape[0], len(hypergraph)))\n",
    "\n",
    "for num, nodes in enumerate(hypergraph.values()):\n",
    "    h[list(nodes), num] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add self-loops to the dataset i.e. for every node $v$, we add a hyper-edge only containing that specific node $e = \\{ v \\}$. This is the standard format expected by the GCNII layers and transform the matrix into a sparse pytorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14655/2226475299.py:6: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  incidence = torch.Tensor(incidence).to_sparse_csr()\n"
     ]
    }
   ],
   "source": [
    "# add self loops\n",
    "h2 = np.eye(x_0.shape[0])\n",
    "incidence = np.hstack((h, h2))\n",
    "\n",
    "# transform to pytorch\n",
    "incidence = torch.Tensor(incidence).to_sparse_csr()\n",
    "incidence = incidence.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load the predefine split in test and train data before we start constructing the HGNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train-test split given by the dataset\n",
    "with open(\"1.pickle\", \"rb\") as H:\n",
    "    splits = pickle.load(H)\n",
    "    train, test = splits[\"train\"], splits[\"test\"]\n",
    "\n",
    "train_idx = torch.LongTensor(train).to(device)\n",
    "test_idx = torch.LongTensor(test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the neural network\n",
    "\n",
    "First, we specify the hyperparameters of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "test_interval = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can generate the corresponding model, optimizer, and loss function with corresponding sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = x_0.shape[1]\n",
    "classes = 7  # current problem has 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UniGCNII(num_classes=classes, in_features=channels, num_layers=3).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to train the created model and evaluate the performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \t Train accuracy: 0.7071428298950195 \t Test accuracy: 0.39291277527809143\n",
      "Epoch: 10 \t Train accuracy: 0.75 \t Test accuracy: 0.4376946985721588\n",
      "Epoch: 15 \t Train accuracy: 0.9357143044471741 \t Test accuracy: 0.6137071847915649\n",
      "Epoch: 20 \t Train accuracy: 0.8714285492897034 \t Test accuracy: 0.45210281014442444\n",
      "Epoch: 25 \t Train accuracy: 0.9071428775787354 \t Test accuracy: 0.5502336621284485\n",
      "Epoch: 30 \t Train accuracy: 0.9785714149475098 \t Test accuracy: 0.5463395714759827\n",
      "Epoch: 35 \t Train accuracy: 0.9785714149475098 \t Test accuracy: 0.5747663378715515\n",
      "Epoch: 40 \t Train accuracy: 0.9857142567634583 \t Test accuracy: 0.5673676133155823\n",
      "Epoch: 45 \t Train accuracy: 0.9428571462631226 \t Test accuracy: 0.552570104598999\n",
      "Epoch: 50 \t Train accuracy: 0.9571428298950195 \t Test accuracy: 0.5607476830482483\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    y_hat = model(x_0, incidence)\n",
    "    loss = loss_fn(y_hat[train_idx], y[train_idx])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Evaluate performance on the validation data\n",
    "    if (epoch + 1) % test_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(x_0, incidence)\n",
    "            y_pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "            train_acc = (y_pred[train_idx] == y[train_idx]).float().mean()\n",
    "            test_acc = (y_pred[test_idx] == y[test_idx]).float().mean()\n",
    "\n",
    "            print(\n",
    "                f\"Epoch: {epoch + 1} \\t Train accuracy: {train_acc} \\t Test accuracy: {test_acc}\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "6db82bc84658dc379dad2324c4569572404d1e9acb031924959aac21ff559da9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
