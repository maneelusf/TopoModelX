{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d52a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from toponetx.classes.simplicial_complex import SimplicialComplex\n",
    "from topomodelx.nn.hypergraph.unigcn_layer import UniGCNLayer\n",
    "from topomodelx.nn.hypergraph.unigcn import UniGCN\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca204a1d",
   "metadata": {},
   "source": [
    "# Train a UNIGCN TNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b0ed66",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "The first step is to import the dataset, MUTAG, a benchmark dataset for graph classification. We then lift each graph into our domain of choice, a hypergraph.\n",
    "\n",
    "We will also retrieve:\n",
    "- input signal on the edges for each of these hypergraphs, as that will be what we feed the model in input\n",
    "- the binary label associated to the hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8075441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root=\"/tmp/MUTAG\", name=\"MUTAG\", use_edge_attr=True)\n",
    "dataset = dataset[:100]\n",
    "hg_list = []\n",
    "x_1_list = []\n",
    "y_list = []\n",
    "for graph in dataset:\n",
    "    hg = SimplicialComplex(to_networkx(graph)).to_hypergraph()\n",
    "    hg_list.append(hg)\n",
    "    x_1_list.append(graph.x)\n",
    "    y_list.append(int(graph.y))\n",
    "\n",
    "incidence_1_list = []\n",
    "for hg in hg_list:\n",
    "    incidence_1 = hg.incidence_matrix()\n",
    "    incidence_1 = torch.from_numpy(incidence_1.todense()).to_sparse_csr()\n",
    "    incidence_1_list.append(incidence_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd1e37",
   "metadata": {},
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the UniGCNLayer class, we create a neural network with stacked layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbc8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_edge = x_1_list[0].shape[1]\n",
    "channels_node = dataset[0].x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniGCN(torch.nn.Module):\n",
    "    \"\"\"Neural network implementation of UniGCN for hypergraph classification.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    channels_edge : int\n",
    "        Dimension of edge features\n",
    "    channels_node : int\n",
    "        Dimension of node features\n",
    "    n_layer : 2\n",
    "        Amount of message passing layers.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels_edge, channels_node, n_layers=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                UniGCNLayer(\n",
    "                    in_channels=channels_edge,\n",
    "                    out_channels=channels_edge,\n",
    "                )\n",
    "            )\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.linear = torch.nn.Linear(channels_edge, 1)\n",
    "\n",
    "    def forward(self, x_1, incidence_1):\n",
    "        \"\"\"Forward computation through layers, then linear layer, then global max pooling.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        x_1 : tensor\n",
    "            shape = [n_edges, channels_edge]\n",
    "            Edge features.\n",
    "\n",
    "        incidence_1 : tensor\n",
    "            shape = [n_nodes, n_edges]\n",
    "            Boundary matrix of rank 1.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        _ : tensor\n",
    "            shape = [1]\n",
    "            Label assigned to whole complex.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_1 = layer(x_1, incidence_1)\n",
    "        pooled_x = torch.max(x_1, dim=0)[0]\n",
    "        return torch.sigmoid(self.linear(pooled_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac19ef6",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, the loss, and an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3d2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UniGCN(channels_edge, channels_node, n_layers=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "crit = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b8f65",
   "metadata": {},
   "source": [
    "Split the dataset into train, val, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505a424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_train, x_1_test = train_test_split(x_1_list, test_size=0.2, shuffle=False)\n",
    "incidence_1_train, incidence_1_test = train_test_split(\n",
    "    incidence_1_list, test_size=0.2, shuffle=False\n",
    ")\n",
    "y_train, y_test = train_test_split(y_list, test_size=0.2, shuffle=False)\n",
    "\n",
    "x_1_train, x_1_val = train_test_split(x_1_train, test_size=0.2, shuffle=False)\n",
    "incidence_1_train, incidence_1_val = train_test_split(\n",
    "    incidence_1_train, test_size=0.2, shuffle=False\n",
    ")\n",
    "y_train, y_val = train_test_split(y_train, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010fd6ad",
   "metadata": {},
   "source": [
    "The following cell performs the training, looping over the network for a low amount of epochs. We keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d64c7e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 165.7614288330078\n",
      "Epoch 0 Validation accuracy: 0.25\n",
      "Epoch 1 loss: 105.14208984375\n",
      "Epoch 1 Validation accuracy: 0.375\n",
      "Epoch 2 loss: 74.9901123046875\n",
      "Epoch 2 Validation accuracy: 0.375\n",
      "Epoch 3 loss: 69.0018539428711\n",
      "Epoch 3 Validation accuracy: 0.375\n",
      "Epoch 4 loss: 71.60785675048828\n",
      "Epoch 4 Validation accuracy: 0.375\n",
      "Epoch 5 loss: 74.9139175415039\n",
      "Epoch 5 Validation accuracy: 0.375\n",
      "Epoch 6 loss: 76.79829406738281\n",
      "Epoch 6 Validation accuracy: 0.5625\n",
      "Epoch 7 loss: 76.701904296875\n",
      "Epoch 7 Validation accuracy: 0.5625\n",
      "Epoch 8 loss: 74.61971282958984\n",
      "Epoch 8 Validation accuracy: 0.5625\n",
      "Epoch 9 loss: 70.78128814697266\n",
      "Epoch 9 Validation accuracy: 0.5625\n",
      "Epoch 10 loss: 65.64765167236328\n",
      "Epoch 10 Validation accuracy: 0.5625\n",
      "Epoch 11 loss: 59.669944763183594\n",
      "Epoch 11 Validation accuracy: 0.625\n",
      "Epoch 12 loss: 53.41646194458008\n",
      "Epoch 12 Validation accuracy: 0.625\n",
      "Epoch 13 loss: 47.65409851074219\n",
      "Epoch 13 Validation accuracy: 0.375\n",
      "Epoch 14 loss: 43.07892608642578\n",
      "Epoch 14 Validation accuracy: 0.375\n",
      "Epoch 15 loss: 40.432987213134766\n",
      "Epoch 15 Validation accuracy: 0.375\n",
      "Epoch 16 loss: 39.787750244140625\n",
      "Epoch 16 Validation accuracy: 0.25\n",
      "Epoch 17 loss: 40.54410171508789\n",
      "Epoch 17 Validation accuracy: 0.25\n",
      "Epoch 18 loss: 41.142616271972656\n",
      "Epoch 18 Validation accuracy: 0.25\n",
      "Epoch 19 loss: 40.32896041870117\n",
      "Epoch 19 Validation accuracy: 0.25\n",
      "Epoch 20 loss: 37.80087661743164\n",
      "Epoch 20 Validation accuracy: 0.5\n",
      "Epoch 21 loss: 34.11060333251953\n",
      "Epoch 21 Validation accuracy: 0.625\n",
      "Epoch 22 loss: 31.921268463134766\n",
      "Epoch 22 Validation accuracy: 0.5625\n",
      "Epoch 23 loss: 31.810203552246094\n",
      "Epoch 23 Validation accuracy: 0.5625\n",
      "Epoch 24 loss: 32.63824462890625\n",
      "Epoch 24 Validation accuracy: 0.5625\n",
      "Epoch 25 loss: 33.06742858886719\n",
      "Epoch 25 Validation accuracy: 0.5625\n",
      "Epoch 26 loss: 32.528656005859375\n",
      "Epoch 26 Validation accuracy: 0.5625\n",
      "Epoch 27 loss: 31.251995086669922\n",
      "Epoch 27 Validation accuracy: 0.5625\n",
      "Epoch 28 loss: 29.908105850219727\n",
      "Epoch 28 Validation accuracy: 0.5\n",
      "Epoch 29 loss: 29.19365119934082\n",
      "Epoch 29 Validation accuracy: 0.5\n",
      "Epoch 30 loss: 29.377145767211914\n",
      "Epoch 30 Validation accuracy: 0.4375\n",
      "Epoch 31 loss: 30.014659881591797\n",
      "Epoch 31 Validation accuracy: 0.4375\n",
      "Epoch 32 loss: 30.360136032104492\n",
      "Epoch 32 Validation accuracy: 0.4375\n",
      "Epoch 33 loss: 30.029949188232422\n",
      "Epoch 33 Validation accuracy: 0.4375\n",
      "Epoch 34 loss: 29.27532386779785\n",
      "Epoch 34 Validation accuracy: 0.5\n",
      "Epoch 35 loss: 28.655189514160156\n",
      "Epoch 35 Validation accuracy: 0.5\n",
      "Epoch 36 loss: 28.52313804626465\n",
      "Epoch 36 Validation accuracy: 0.5625\n",
      "Epoch 37 loss: 28.78830337524414\n",
      "Epoch 37 Validation accuracy: 0.5625\n",
      "Epoch 38 loss: 29.068376541137695\n",
      "Epoch 38 Validation accuracy: 0.5625\n",
      "Epoch 39 loss: 29.059688568115234\n",
      "Epoch 39 Validation accuracy: 0.5625\n",
      "Epoch 40 loss: 28.733675003051758\n",
      "Epoch 40 Validation accuracy: 0.5625\n",
      "Epoch 41 loss: 28.30593490600586\n",
      "Epoch 41 Validation accuracy: 0.5\n",
      "Epoch 42 loss: 28.037002563476562\n",
      "Epoch 42 Validation accuracy: 0.5\n",
      "Epoch 43 loss: 28.041772842407227\n",
      "Epoch 43 Validation accuracy: 0.5\n",
      "Epoch 44 loss: 28.18195915222168\n",
      "Epoch 44 Validation accuracy: 0.5\n",
      "Epoch 45 loss: 28.216632843017578\n",
      "Epoch 45 Validation accuracy: 0.5\n",
      "Epoch 46 loss: 28.03668212890625\n",
      "Epoch 46 Validation accuracy: 0.5\n",
      "Epoch 47 loss: 27.747711181640625\n",
      "Epoch 47 Validation accuracy: 0.5\n",
      "Epoch 48 loss: 27.536235809326172\n",
      "Epoch 48 Validation accuracy: 0.5625\n",
      "Epoch 49 loss: 27.486495971679688\n",
      "Epoch 49 Validation accuracy: 0.5625\n",
      "Epoch 50 loss: 27.524477005004883\n",
      "Epoch 50 Validation accuracy: 0.5625\n",
      "Epoch 51 loss: 27.51424217224121\n",
      "Epoch 51 Validation accuracy: 0.5625\n",
      "Epoch 52 loss: 27.388534545898438\n",
      "Epoch 52 Validation accuracy: 0.5625\n",
      "Epoch 53 loss: 27.19575309753418\n",
      "Epoch 53 Validation accuracy: 0.5625\n",
      "Epoch 54 loss: 27.040342330932617\n",
      "Epoch 54 Validation accuracy: 0.5\n",
      "Epoch 55 loss: 26.979869842529297\n",
      "Epoch 55 Validation accuracy: 0.5\n",
      "Epoch 56 loss: 26.97402572631836\n",
      "Epoch 56 Validation accuracy: 0.5\n",
      "Epoch 57 loss: 26.93471908569336\n",
      "Epoch 57 Validation accuracy: 0.5\n",
      "Epoch 58 loss: 26.82194709777832\n",
      "Epoch 58 Validation accuracy: 0.5\n",
      "Epoch 59 loss: 26.677967071533203\n",
      "Epoch 59 Validation accuracy: 0.5\n",
      "Epoch 60 loss: 26.571840286254883\n",
      "Epoch 60 Validation accuracy: 0.5625\n",
      "Epoch 61 loss: 26.52323341369629\n",
      "Epoch 61 Validation accuracy: 0.5625\n",
      "Epoch 62 loss: 26.490306854248047\n",
      "Epoch 62 Validation accuracy: 0.5625\n",
      "Epoch 63 loss: 26.423433303833008\n",
      "Epoch 63 Validation accuracy: 0.5\n",
      "Epoch 64 loss: 26.317480087280273\n",
      "Epoch 64 Validation accuracy: 0.5\n",
      "Epoch 65 loss: 26.21135139465332\n",
      "Epoch 65 Validation accuracy: 0.5\n",
      "Epoch 66 loss: 26.140106201171875\n",
      "Epoch 66 Validation accuracy: 0.5\n",
      "Epoch 67 loss: 26.096113204956055\n",
      "Epoch 67 Validation accuracy: 0.5\n",
      "Epoch 68 loss: 26.042531967163086\n",
      "Epoch 68 Validation accuracy: 0.5\n",
      "Epoch 69 loss: 25.95944595336914\n",
      "Epoch 69 Validation accuracy: 0.5\n",
      "Epoch 70 loss: 25.866323471069336\n",
      "Epoch 70 Validation accuracy: 0.5\n",
      "Epoch 71 loss: 25.793888092041016\n",
      "Epoch 71 Validation accuracy: 0.5\n",
      "Epoch 72 loss: 25.74404525756836\n",
      "Epoch 72 Validation accuracy: 0.5\n",
      "Epoch 73 loss: 25.69246482849121\n",
      "Epoch 73 Validation accuracy: 0.5\n",
      "Epoch 74 loss: 25.62270164489746\n",
      "Epoch 74 Validation accuracy: 0.5\n",
      "Epoch 75 loss: 25.54464340209961\n",
      "Epoch 75 Validation accuracy: 0.4375\n",
      "Epoch 76 loss: 25.47838020324707\n",
      "Epoch 76 Validation accuracy: 0.4375\n",
      "Epoch 77 loss: 25.426912307739258\n",
      "Epoch 77 Validation accuracy: 0.4375\n",
      "Epoch 78 loss: 25.373062133789062\n",
      "Epoch 78 Validation accuracy: 0.4375\n",
      "Epoch 79 loss: 25.305171966552734\n",
      "Epoch 79 Validation accuracy: 0.4375\n",
      "Epoch 80 loss: 25.233936309814453\n",
      "Epoch 80 Validation accuracy: 0.4375\n",
      "Epoch 81 loss: 25.17312240600586\n",
      "Epoch 81 Validation accuracy: 0.4375\n",
      "Epoch 82 loss: 25.1207332611084\n",
      "Epoch 82 Validation accuracy: 0.4375\n",
      "Epoch 83 loss: 25.062572479248047\n",
      "Epoch 83 Validation accuracy: 0.4375\n",
      "Epoch 84 loss: 24.993520736694336\n",
      "Epoch 84 Validation accuracy: 0.4375\n",
      "Epoch 85 loss: 24.925992965698242\n",
      "Epoch 85 Validation accuracy: 0.4375\n",
      "Epoch 86 loss: 24.866220474243164\n",
      "Epoch 86 Validation accuracy: 0.4375\n",
      "Epoch 87 loss: 24.808015823364258\n",
      "Epoch 87 Validation accuracy: 0.4375\n",
      "Epoch 88 loss: 24.74358558654785\n",
      "Epoch 88 Validation accuracy: 0.4375\n",
      "Epoch 89 loss: 24.676074981689453\n",
      "Epoch 89 Validation accuracy: 0.4375\n",
      "Epoch 90 loss: 24.613107681274414\n",
      "Epoch 90 Validation accuracy: 0.4375\n",
      "Epoch 91 loss: 24.55487823486328\n",
      "Epoch 91 Validation accuracy: 0.4375\n",
      "Epoch 92 loss: 24.49464225769043\n",
      "Epoch 92 Validation accuracy: 0.4375\n",
      "Epoch 93 loss: 24.431529998779297\n",
      "Epoch 93 Validation accuracy: 0.4375\n",
      "Epoch 94 loss: 24.371583938598633\n",
      "Epoch 94 Validation accuracy: 0.4375\n",
      "Epoch 95 loss: 24.31517791748047\n",
      "Epoch 95 Validation accuracy: 0.4375\n",
      "Epoch 96 loss: 24.258554458618164\n",
      "Epoch 96 Validation accuracy: 0.4375\n",
      "Epoch 97 loss: 24.196821212768555\n",
      "Epoch 97 Validation accuracy: 0.4375\n",
      "Epoch 98 loss: 24.138710021972656\n",
      "Epoch 98 Validation accuracy: 0.4375\n",
      "Epoch 99 loss: 24.08538246154785\n",
      "Epoch 99 Validation accuracy: 0.4375\n",
      "Epoch 100 loss: 24.02964973449707\n",
      "Epoch 100 Validation accuracy: 0.4375\n",
      "Epoch 101 loss: 23.969528198242188\n",
      "Epoch 101 Validation accuracy: 0.4375\n",
      "Epoch 102 loss: 23.91205406188965\n",
      "Epoch 102 Validation accuracy: 0.4375\n",
      "Epoch 103 loss: 23.85782241821289\n",
      "Epoch 103 Validation accuracy: 0.4375\n",
      "Epoch 104 loss: 23.801481246948242\n",
      "Epoch 104 Validation accuracy: 0.4375\n",
      "Epoch 105 loss: 23.744592666625977\n",
      "Epoch 105 Validation accuracy: 0.4375\n",
      "Epoch 106 loss: 23.691757202148438\n",
      "Epoch 106 Validation accuracy: 0.4375\n",
      "Epoch 107 loss: 23.64069175720215\n",
      "Epoch 107 Validation accuracy: 0.4375\n",
      "Epoch 108 loss: 23.58679962158203\n",
      "Epoch 108 Validation accuracy: 0.4375\n",
      "Epoch 109 loss: 23.53645896911621\n",
      "Epoch 109 Validation accuracy: 0.4375\n",
      "Epoch 110 loss: 23.486536026000977\n",
      "Epoch 110 Validation accuracy: 0.4375\n",
      "Epoch 111 loss: 23.4338436126709\n",
      "Epoch 111 Validation accuracy: 0.4375\n",
      "Epoch 112 loss: 23.382482528686523\n",
      "Epoch 112 Validation accuracy: 0.4375\n",
      "Epoch 113 loss: 23.333112716674805\n",
      "Epoch 113 Validation accuracy: 0.4375\n",
      "Epoch 114 loss: 23.28126335144043\n",
      "Epoch 114 Validation accuracy: 0.4375\n",
      "Epoch 115 loss: 23.232397079467773\n",
      "Epoch 115 Validation accuracy: 0.4375\n",
      "Epoch 116 loss: 23.183761596679688\n",
      "Epoch 116 Validation accuracy: 0.4375\n",
      "Epoch 117 loss: 23.13381004333496\n",
      "Epoch 117 Validation accuracy: 0.4375\n",
      "Epoch 118 loss: 23.084972381591797\n",
      "Epoch 118 Validation accuracy: 0.4375\n",
      "Epoch 119 loss: 23.0375919342041\n",
      "Epoch 119 Validation accuracy: 0.4375\n",
      "Epoch 120 loss: 22.988269805908203\n",
      "Epoch 120 Validation accuracy: 0.4375\n",
      "Epoch 121 loss: 22.94058609008789\n",
      "Epoch 121 Validation accuracy: 0.4375\n",
      "Epoch 122 loss: 22.89324951171875\n",
      "Epoch 122 Validation accuracy: 0.4375\n",
      "Epoch 123 loss: 22.844738006591797\n",
      "Epoch 123 Validation accuracy: 0.4375\n",
      "Epoch 124 loss: 22.798208236694336\n",
      "Epoch 124 Validation accuracy: 0.4375\n",
      "Epoch 125 loss: 22.751218795776367\n",
      "Epoch 125 Validation accuracy: 0.4375\n",
      "Epoch 126 loss: 22.703603744506836\n",
      "Epoch 126 Validation accuracy: 0.4375\n",
      "Epoch 127 loss: 22.657014846801758\n",
      "Epoch 127 Validation accuracy: 0.4375\n",
      "Epoch 128 loss: 22.609346389770508\n",
      "Epoch 128 Validation accuracy: 0.4375\n",
      "Epoch 129 loss: 22.562883377075195\n",
      "Epoch 129 Validation accuracy: 0.4375\n",
      "Epoch 130 loss: 22.51540756225586\n",
      "Epoch 130 Validation accuracy: 0.4375\n",
      "Epoch 131 loss: 22.469411849975586\n",
      "Epoch 131 Validation accuracy: 0.4375\n",
      "Epoch 132 loss: 22.422489166259766\n",
      "Epoch 132 Validation accuracy: 0.4375\n",
      "Epoch 133 loss: 22.37441635131836\n",
      "Epoch 133 Validation accuracy: 0.4375\n",
      "Epoch 134 loss: 22.329015731811523\n",
      "Epoch 134 Validation accuracy: 0.4375\n",
      "Epoch 135 loss: 22.28156852722168\n",
      "Epoch 135 Validation accuracy: 0.4375\n",
      "Epoch 136 loss: 22.23576545715332\n",
      "Epoch 136 Validation accuracy: 0.4375\n",
      "Epoch 137 loss: 22.190256118774414\n",
      "Epoch 137 Validation accuracy: 0.4375\n",
      "Epoch 138 loss: 22.145503997802734\n",
      "Epoch 138 Validation accuracy: 0.4375\n",
      "Epoch 139 loss: 22.10194969177246\n",
      "Epoch 139 Validation accuracy: 0.4375\n",
      "Epoch 140 loss: 22.057546615600586\n",
      "Epoch 140 Validation accuracy: 0.4375\n",
      "Epoch 141 loss: 22.01426124572754\n",
      "Epoch 141 Validation accuracy: 0.4375\n",
      "Epoch 142 loss: 21.970149993896484\n",
      "Epoch 142 Validation accuracy: 0.4375\n",
      "Epoch 143 loss: 21.926389694213867\n",
      "Epoch 143 Validation accuracy: 0.4375\n",
      "Epoch 144 loss: 21.883451461791992\n",
      "Epoch 144 Validation accuracy: 0.4375\n",
      "Epoch 145 loss: 21.840131759643555\n",
      "Epoch 145 Validation accuracy: 0.4375\n",
      "Epoch 146 loss: 21.796890258789062\n",
      "Epoch 146 Validation accuracy: 0.4375\n",
      "Epoch 147 loss: 21.75390625\n",
      "Epoch 147 Validation accuracy: 0.4375\n",
      "Epoch 148 loss: 21.71155548095703\n",
      "Epoch 148 Validation accuracy: 0.4375\n",
      "Epoch 149 loss: 21.6693115234375\n",
      "Epoch 149 Validation accuracy: 0.4375\n",
      "Epoch 150 loss: 21.626955032348633\n",
      "Epoch 150 Validation accuracy: 0.4375\n",
      "Epoch 151 loss: 21.588376998901367\n",
      "Epoch 151 Validation accuracy: 0.4375\n",
      "Epoch 152 loss: 21.551286697387695\n",
      "Epoch 152 Validation accuracy: 0.4375\n",
      "Epoch 153 loss: 21.512758255004883\n",
      "Epoch 153 Validation accuracy: 0.4375\n",
      "Epoch 154 loss: 21.47568702697754\n",
      "Epoch 154 Validation accuracy: 0.4375\n",
      "Epoch 155 loss: 21.43646240234375\n",
      "Epoch 155 Validation accuracy: 0.4375\n",
      "Epoch 156 loss: 21.399036407470703\n",
      "Epoch 156 Validation accuracy: 0.4375\n",
      "Epoch 157 loss: 21.360443115234375\n",
      "Epoch 157 Validation accuracy: 0.4375\n",
      "Epoch 158 loss: 21.322185516357422\n",
      "Epoch 158 Validation accuracy: 0.4375\n",
      "Epoch 159 loss: 21.285079956054688\n",
      "Epoch 159 Validation accuracy: 0.4375\n",
      "Epoch 160 loss: 21.248210906982422\n",
      "Epoch 160 Validation accuracy: 0.4375\n",
      "Epoch 161 loss: 21.211536407470703\n",
      "Epoch 161 Validation accuracy: 0.4375\n",
      "Epoch 162 loss: 21.174375534057617\n",
      "Epoch 162 Validation accuracy: 0.4375\n",
      "Epoch 163 loss: 21.137815475463867\n",
      "Epoch 163 Validation accuracy: 0.4375\n",
      "Epoch 164 loss: 21.10064697265625\n",
      "Epoch 164 Validation accuracy: 0.4375\n",
      "Epoch 165 loss: 21.065513610839844\n",
      "Epoch 165 Validation accuracy: 0.4375\n",
      "Epoch 166 loss: 21.028472900390625\n",
      "Epoch 166 Validation accuracy: 0.4375\n",
      "Epoch 167 loss: 20.99333953857422\n",
      "Epoch 167 Validation accuracy: 0.4375\n",
      "Epoch 168 loss: 20.954837799072266\n",
      "Epoch 168 Validation accuracy: 0.4375\n",
      "Epoch 169 loss: 20.91936492919922\n",
      "Epoch 169 Validation accuracy: 0.4375\n",
      "Epoch 170 loss: 20.882925033569336\n",
      "Epoch 170 Validation accuracy: 0.4375\n",
      "Epoch 171 loss: 20.8482723236084\n",
      "Epoch 171 Validation accuracy: 0.4375\n",
      "Epoch 172 loss: 20.812274932861328\n",
      "Epoch 172 Validation accuracy: 0.4375\n",
      "Epoch 173 loss: 20.777469635009766\n",
      "Epoch 173 Validation accuracy: 0.4375\n",
      "Epoch 174 loss: 20.742053985595703\n",
      "Epoch 174 Validation accuracy: 0.4375\n",
      "Epoch 175 loss: 20.70737075805664\n",
      "Epoch 175 Validation accuracy: 0.4375\n",
      "Epoch 176 loss: 20.670494079589844\n",
      "Epoch 176 Validation accuracy: 0.4375\n",
      "Epoch 177 loss: 20.636764526367188\n",
      "Epoch 177 Validation accuracy: 0.4375\n",
      "Epoch 178 loss: 20.602548599243164\n",
      "Epoch 178 Validation accuracy: 0.4375\n",
      "Epoch 179 loss: 20.568532943725586\n",
      "Epoch 179 Validation accuracy: 0.5\n",
      "Epoch 180 loss: 20.53515625\n",
      "Epoch 180 Validation accuracy: 0.5\n",
      "Epoch 181 loss: 20.499996185302734\n",
      "Epoch 181 Validation accuracy: 0.5\n",
      "Epoch 182 loss: 20.46674346923828\n",
      "Epoch 182 Validation accuracy: 0.5\n",
      "Epoch 183 loss: 20.43351173400879\n",
      "Epoch 183 Validation accuracy: 0.5\n",
      "Epoch 184 loss: 20.40045928955078\n",
      "Epoch 184 Validation accuracy: 0.5\n",
      "Epoch 185 loss: 20.36823272705078\n",
      "Epoch 185 Validation accuracy: 0.5\n",
      "Epoch 186 loss: 20.336650848388672\n",
      "Epoch 186 Validation accuracy: 0.5\n",
      "Epoch 187 loss: 20.303945541381836\n",
      "Epoch 187 Validation accuracy: 0.5\n",
      "Epoch 188 loss: 20.27122688293457\n",
      "Epoch 188 Validation accuracy: 0.5\n",
      "Epoch 189 loss: 20.23938751220703\n",
      "Epoch 189 Validation accuracy: 0.5\n",
      "Epoch 190 loss: 20.208730697631836\n",
      "Epoch 190 Validation accuracy: 0.5\n",
      "Epoch 191 loss: 20.17889976501465\n",
      "Epoch 191 Validation accuracy: 0.5\n",
      "Epoch 192 loss: 20.14697265625\n",
      "Epoch 192 Validation accuracy: 0.5\n",
      "Epoch 193 loss: 20.116243362426758\n",
      "Epoch 193 Validation accuracy: 0.5\n",
      "Epoch 194 loss: 20.088253021240234\n",
      "Epoch 194 Validation accuracy: 0.5\n",
      "Epoch 195 loss: 20.060087203979492\n",
      "Epoch 195 Validation accuracy: 0.5\n",
      "Epoch 196 loss: 20.031740188598633\n",
      "Epoch 196 Validation accuracy: 0.5\n",
      "Epoch 197 loss: 20.00320816040039\n",
      "Epoch 197 Validation accuracy: 0.5\n",
      "Epoch 198 loss: 19.973133087158203\n",
      "Epoch 198 Validation accuracy: 0.5\n",
      "Epoch 199 loss: 19.94407844543457\n",
      "Epoch 199 Validation accuracy: 0.5\n",
      "Epoch 200 loss: 19.915699005126953\n",
      "Epoch 200 Validation accuracy: 0.5\n",
      "Epoch 201 loss: 19.890426635742188\n",
      "Epoch 201 Validation accuracy: 0.5\n",
      "Epoch 202 loss: 19.85906219482422\n",
      "Epoch 202 Validation accuracy: 0.5\n",
      "Epoch 203 loss: 19.83558464050293\n",
      "Epoch 203 Validation accuracy: 0.5\n",
      "Epoch 204 loss: 19.807849884033203\n",
      "Epoch 204 Validation accuracy: 0.5\n",
      "Epoch 205 loss: 19.78500747680664\n",
      "Epoch 205 Validation accuracy: 0.5\n",
      "Epoch 206 loss: 19.758363723754883\n",
      "Epoch 206 Validation accuracy: 0.5\n",
      "Epoch 207 loss: 19.73211097717285\n",
      "Epoch 207 Validation accuracy: 0.5\n",
      "Epoch 208 loss: 19.7080135345459\n",
      "Epoch 208 Validation accuracy: 0.5\n",
      "Epoch 209 loss: 19.683975219726562\n",
      "Epoch 209 Validation accuracy: 0.5\n",
      "Epoch 210 loss: 19.66098403930664\n",
      "Epoch 210 Validation accuracy: 0.5\n",
      "Epoch 211 loss: 19.636838912963867\n",
      "Epoch 211 Validation accuracy: 0.5\n",
      "Epoch 212 loss: 19.613290786743164\n",
      "Epoch 212 Validation accuracy: 0.5\n",
      "Epoch 213 loss: 19.589847564697266\n",
      "Epoch 213 Validation accuracy: 0.5\n",
      "Epoch 214 loss: 19.572372436523438\n",
      "Epoch 214 Validation accuracy: 0.5\n",
      "Epoch 215 loss: 19.54673194885254\n",
      "Epoch 215 Validation accuracy: 0.5\n",
      "Epoch 216 loss: 19.523332595825195\n",
      "Epoch 216 Validation accuracy: 0.5\n",
      "Epoch 217 loss: 19.50444221496582\n",
      "Epoch 217 Validation accuracy: 0.5\n",
      "Epoch 218 loss: 19.4801082611084\n",
      "Epoch 218 Validation accuracy: 0.5\n",
      "Epoch 219 loss: 19.457857131958008\n",
      "Epoch 219 Validation accuracy: 0.5\n",
      "Epoch 220 loss: 19.437654495239258\n",
      "Epoch 220 Validation accuracy: 0.5\n",
      "Epoch 221 loss: 19.414960861206055\n",
      "Epoch 221 Validation accuracy: 0.5\n",
      "Epoch 222 loss: 19.394716262817383\n",
      "Epoch 222 Validation accuracy: 0.5\n",
      "Epoch 223 loss: 19.371318817138672\n",
      "Epoch 223 Validation accuracy: 0.5\n",
      "Epoch 224 loss: 19.35015869140625\n",
      "Epoch 224 Validation accuracy: 0.5\n",
      "Epoch 225 loss: 19.325063705444336\n",
      "Epoch 225 Validation accuracy: 0.5\n",
      "Epoch 226 loss: 19.301170349121094\n",
      "Epoch 226 Validation accuracy: 0.5\n",
      "Epoch 227 loss: 19.273983001708984\n",
      "Epoch 227 Validation accuracy: 0.5\n",
      "Epoch 228 loss: 19.24747657775879\n",
      "Epoch 228 Validation accuracy: 0.5\n",
      "Epoch 229 loss: 19.21958351135254\n",
      "Epoch 229 Validation accuracy: 0.5\n",
      "Epoch 230 loss: 19.186161041259766\n",
      "Epoch 230 Validation accuracy: 0.5\n",
      "Epoch 231 loss: 19.158851623535156\n",
      "Epoch 231 Validation accuracy: 0.5\n",
      "Epoch 232 loss: 19.130292892456055\n",
      "Epoch 232 Validation accuracy: 0.5\n",
      "Epoch 233 loss: 19.100955963134766\n",
      "Epoch 233 Validation accuracy: 0.5\n",
      "Epoch 234 loss: 19.073450088500977\n",
      "Epoch 234 Validation accuracy: 0.5\n",
      "Epoch 235 loss: 19.044172286987305\n",
      "Epoch 235 Validation accuracy: 0.5\n",
      "Epoch 236 loss: 19.018007278442383\n",
      "Epoch 236 Validation accuracy: 0.5\n",
      "Epoch 237 loss: 18.990388870239258\n",
      "Epoch 237 Validation accuracy: 0.5\n",
      "Epoch 238 loss: 18.963735580444336\n",
      "Epoch 238 Validation accuracy: 0.5\n",
      "Epoch 239 loss: 18.93748664855957\n",
      "Epoch 239 Validation accuracy: 0.5\n",
      "Epoch 240 loss: 18.909765243530273\n",
      "Epoch 240 Validation accuracy: 0.5\n",
      "Epoch 241 loss: 18.88081932067871\n",
      "Epoch 241 Validation accuracy: 0.5\n",
      "Epoch 242 loss: 18.84971809387207\n",
      "Epoch 242 Validation accuracy: 0.5\n",
      "Epoch 243 loss: 18.828895568847656\n",
      "Epoch 243 Validation accuracy: 0.5\n",
      "Epoch 244 loss: 18.821622848510742\n",
      "Epoch 244 Validation accuracy: 0.5\n",
      "Epoch 245 loss: 18.816598892211914\n",
      "Epoch 245 Validation accuracy: 0.5\n",
      "Epoch 246 loss: 18.811264038085938\n",
      "Epoch 246 Validation accuracy: 0.5\n",
      "Epoch 247 loss: 18.80107879638672\n",
      "Epoch 247 Validation accuracy: 0.5\n",
      "Epoch 248 loss: 18.786951065063477\n",
      "Epoch 248 Validation accuracy: 0.5\n",
      "Epoch 249 loss: 18.77764129638672\n",
      "Epoch 249 Validation accuracy: 0.5\n",
      "Epoch 250 loss: 18.763965606689453\n",
      "Epoch 250 Validation accuracy: 0.5\n",
      "Epoch 251 loss: 18.749052047729492\n",
      "Epoch 251 Validation accuracy: 0.5\n",
      "Epoch 252 loss: 18.732437133789062\n",
      "Epoch 252 Validation accuracy: 0.5\n",
      "Epoch 253 loss: 18.715450286865234\n",
      "Epoch 253 Validation accuracy: 0.5\n",
      "Epoch 254 loss: 18.699914932250977\n",
      "Epoch 254 Validation accuracy: 0.5\n",
      "Epoch 255 loss: 18.693506240844727\n",
      "Epoch 255 Validation accuracy: 0.5\n",
      "Epoch 256 loss: 18.68547248840332\n",
      "Epoch 256 Validation accuracy: 0.5\n",
      "Epoch 257 loss: 18.67757797241211\n",
      "Epoch 257 Validation accuracy: 0.5\n",
      "Epoch 258 loss: 18.666513442993164\n",
      "Epoch 258 Validation accuracy: 0.5\n",
      "Epoch 259 loss: 18.654096603393555\n",
      "Epoch 259 Validation accuracy: 0.5\n",
      "Epoch 260 loss: 18.643943786621094\n",
      "Epoch 260 Validation accuracy: 0.5\n",
      "Epoch 261 loss: 18.632356643676758\n",
      "Epoch 261 Validation accuracy: 0.5\n",
      "Epoch 262 loss: 18.62032127380371\n",
      "Epoch 262 Validation accuracy: 0.5\n",
      "Epoch 263 loss: 18.606496810913086\n",
      "Epoch 263 Validation accuracy: 0.5\n",
      "Epoch 264 loss: 18.593935012817383\n",
      "Epoch 264 Validation accuracy: 0.5\n",
      "Epoch 265 loss: 18.58778190612793\n",
      "Epoch 265 Validation accuracy: 0.5\n",
      "Epoch 266 loss: 18.581344604492188\n",
      "Epoch 266 Validation accuracy: 0.5\n",
      "Epoch 267 loss: 18.571155548095703\n",
      "Epoch 267 Validation accuracy: 0.5\n",
      "Epoch 268 loss: 18.55927276611328\n",
      "Epoch 268 Validation accuracy: 0.5\n",
      "Epoch 269 loss: 18.548603057861328\n",
      "Epoch 269 Validation accuracy: 0.5\n",
      "Epoch 270 loss: 18.540870666503906\n",
      "Epoch 270 Validation accuracy: 0.5\n",
      "Epoch 271 loss: 18.533618927001953\n",
      "Epoch 271 Validation accuracy: 0.5\n",
      "Epoch 272 loss: 18.524255752563477\n",
      "Epoch 272 Validation accuracy: 0.5\n",
      "Epoch 273 loss: 18.51365852355957\n",
      "Epoch 273 Validation accuracy: 0.5\n",
      "Epoch 274 loss: 18.50380516052246\n",
      "Epoch 274 Validation accuracy: 0.5\n",
      "Epoch 275 loss: 18.49231719970703\n",
      "Epoch 275 Validation accuracy: 0.5\n",
      "Epoch 276 loss: 18.486114501953125\n",
      "Epoch 276 Validation accuracy: 0.5\n",
      "Epoch 277 loss: 18.48149871826172\n",
      "Epoch 277 Validation accuracy: 0.5\n",
      "Epoch 278 loss: 18.47393226623535\n",
      "Epoch 278 Validation accuracy: 0.5\n",
      "Epoch 279 loss: 18.46294403076172\n",
      "Epoch 279 Validation accuracy: 0.5\n",
      "Epoch 280 loss: 18.452980041503906\n",
      "Epoch 280 Validation accuracy: 0.5\n",
      "Epoch 281 loss: 18.445396423339844\n",
      "Epoch 281 Validation accuracy: 0.5\n",
      "Epoch 282 loss: 18.438392639160156\n",
      "Epoch 282 Validation accuracy: 0.5\n",
      "Epoch 283 loss: 18.430234909057617\n",
      "Epoch 283 Validation accuracy: 0.5\n",
      "Epoch 284 loss: 18.423768997192383\n",
      "Epoch 284 Validation accuracy: 0.5\n",
      "Epoch 285 loss: 18.41377067565918\n",
      "Epoch 285 Validation accuracy: 0.5\n",
      "Epoch 286 loss: 18.404756546020508\n",
      "Epoch 286 Validation accuracy: 0.5\n",
      "Epoch 287 loss: 18.39927864074707\n",
      "Epoch 287 Validation accuracy: 0.5\n",
      "Epoch 288 loss: 18.39226722717285\n",
      "Epoch 288 Validation accuracy: 0.5\n",
      "Epoch 289 loss: 18.377662658691406\n",
      "Epoch 289 Validation accuracy: 0.5\n",
      "Epoch 290 loss: 18.34791374206543\n",
      "Epoch 290 Validation accuracy: 0.5\n",
      "Epoch 291 loss: 18.318614959716797\n",
      "Epoch 291 Validation accuracy: 0.5\n",
      "Epoch 292 loss: 18.283618927001953\n",
      "Epoch 292 Validation accuracy: 0.5\n",
      "Epoch 293 loss: 18.244592666625977\n",
      "Epoch 293 Validation accuracy: 0.5\n",
      "Epoch 294 loss: 18.2094669342041\n",
      "Epoch 294 Validation accuracy: 0.5\n",
      "Epoch 295 loss: 18.179485321044922\n",
      "Epoch 295 Validation accuracy: 0.5\n",
      "Epoch 296 loss: 18.153244018554688\n",
      "Epoch 296 Validation accuracy: 0.5\n",
      "Epoch 297 loss: 18.13216209411621\n",
      "Epoch 297 Validation accuracy: 0.5\n",
      "Epoch 298 loss: 18.107423782348633\n",
      "Epoch 298 Validation accuracy: 0.5\n",
      "Epoch 299 loss: 18.083436965942383\n",
      "Epoch 299 Validation accuracy: 0.5\n",
      "Epoch 300 loss: 18.06333351135254\n",
      "Epoch 300 Validation accuracy: 0.5\n",
      "Epoch 301 loss: 18.042098999023438\n",
      "Epoch 301 Validation accuracy: 0.5\n",
      "Epoch 302 loss: 18.019763946533203\n",
      "Epoch 302 Validation accuracy: 0.5625\n",
      "Epoch 303 loss: 17.998645782470703\n",
      "Epoch 303 Validation accuracy: 0.5625\n",
      "Epoch 304 loss: 17.977785110473633\n",
      "Epoch 304 Validation accuracy: 0.5625\n",
      "Epoch 305 loss: 17.955106735229492\n",
      "Epoch 305 Validation accuracy: 0.5625\n",
      "Epoch 306 loss: 17.93370819091797\n",
      "Epoch 306 Validation accuracy: 0.5625\n",
      "Epoch 307 loss: 17.90960121154785\n",
      "Epoch 307 Validation accuracy: 0.5625\n",
      "Epoch 308 loss: 17.893733978271484\n",
      "Epoch 308 Validation accuracy: 0.5625\n",
      "Epoch 309 loss: 17.871891021728516\n",
      "Epoch 309 Validation accuracy: 0.5\n",
      "Epoch 310 loss: 17.86931037902832\n",
      "Epoch 310 Validation accuracy: 0.5625\n",
      "Epoch 311 loss: 17.862485885620117\n",
      "Epoch 311 Validation accuracy: 0.5\n",
      "Epoch 312 loss: 17.836353302001953\n",
      "Epoch 312 Validation accuracy: 0.5625\n",
      "Epoch 313 loss: 17.833049774169922\n",
      "Epoch 313 Validation accuracy: 0.5\n",
      "Epoch 314 loss: 17.813018798828125\n",
      "Epoch 314 Validation accuracy: 0.5\n",
      "Epoch 315 loss: 17.787582397460938\n",
      "Epoch 315 Validation accuracy: 0.5\n",
      "Epoch 316 loss: 17.774547576904297\n",
      "Epoch 316 Validation accuracy: 0.5\n",
      "Epoch 317 loss: 17.76090431213379\n",
      "Epoch 317 Validation accuracy: 0.5625\n",
      "Epoch 318 loss: 17.735597610473633\n",
      "Epoch 318 Validation accuracy: 0.5\n",
      "Epoch 319 loss: 17.702381134033203\n",
      "Epoch 319 Validation accuracy: 0.5625\n",
      "Epoch 320 loss: 17.67142677307129\n",
      "Epoch 320 Validation accuracy: 0.5625\n",
      "Epoch 321 loss: 17.644575119018555\n",
      "Epoch 321 Validation accuracy: 0.5\n",
      "Epoch 322 loss: 17.65545082092285\n",
      "Epoch 322 Validation accuracy: 0.5625\n",
      "Epoch 323 loss: 17.642303466796875\n",
      "Epoch 323 Validation accuracy: 0.5\n",
      "Epoch 324 loss: 17.65273666381836\n",
      "Epoch 324 Validation accuracy: 0.5625\n",
      "Epoch 325 loss: 17.633018493652344\n",
      "Epoch 325 Validation accuracy: 0.5\n",
      "Epoch 326 loss: 17.59491539001465\n",
      "Epoch 326 Validation accuracy: 0.5625\n",
      "Epoch 327 loss: 17.563846588134766\n",
      "Epoch 327 Validation accuracy: 0.5\n",
      "Epoch 328 loss: 17.534692764282227\n",
      "Epoch 328 Validation accuracy: 0.5\n",
      "Epoch 329 loss: 17.505828857421875\n",
      "Epoch 329 Validation accuracy: 0.5\n",
      "Epoch 330 loss: 17.48617935180664\n",
      "Epoch 330 Validation accuracy: 0.5\n",
      "Epoch 331 loss: 17.467458724975586\n",
      "Epoch 331 Validation accuracy: 0.5\n",
      "Epoch 332 loss: 17.44194984436035\n",
      "Epoch 332 Validation accuracy: 0.5\n",
      "Epoch 333 loss: 17.45574951171875\n",
      "Epoch 333 Validation accuracy: 0.5625\n",
      "Epoch 334 loss: 17.412145614624023\n",
      "Epoch 334 Validation accuracy: 0.5\n",
      "Epoch 335 loss: 17.404067993164062\n",
      "Epoch 335 Validation accuracy: 0.5\n",
      "Epoch 336 loss: 17.434274673461914\n",
      "Epoch 336 Validation accuracy: 0.5\n",
      "Epoch 337 loss: 17.441726684570312\n",
      "Epoch 337 Validation accuracy: 0.5\n",
      "Epoch 338 loss: 17.406042098999023\n",
      "Epoch 338 Validation accuracy: 0.5\n",
      "Epoch 339 loss: 17.34653663635254\n",
      "Epoch 339 Validation accuracy: 0.5\n",
      "Epoch 340 loss: 17.299779891967773\n",
      "Epoch 340 Validation accuracy: 0.5\n",
      "Epoch 341 loss: 17.279638290405273\n",
      "Epoch 341 Validation accuracy: 0.5\n",
      "Epoch 342 loss: 17.26668930053711\n",
      "Epoch 342 Validation accuracy: 0.5\n",
      "Epoch 343 loss: 17.24495506286621\n",
      "Epoch 343 Validation accuracy: 0.5\n",
      "Epoch 344 loss: 17.262187957763672\n",
      "Epoch 344 Validation accuracy: 0.5\n",
      "Epoch 345 loss: 17.213422775268555\n",
      "Epoch 345 Validation accuracy: 0.5\n",
      "Epoch 346 loss: 17.14848518371582\n",
      "Epoch 346 Validation accuracy: 0.5\n",
      "Epoch 347 loss: 17.14635467529297\n",
      "Epoch 347 Validation accuracy: 0.5\n",
      "Epoch 348 loss: 17.167444229125977\n",
      "Epoch 348 Validation accuracy: 0.5\n",
      "Epoch 349 loss: 17.167804718017578\n",
      "Epoch 349 Validation accuracy: 0.5\n",
      "Epoch 350 loss: 17.138286590576172\n",
      "Epoch 350 Validation accuracy: 0.5\n",
      "Epoch 351 loss: 17.078554153442383\n",
      "Epoch 351 Validation accuracy: 0.5\n",
      "Epoch 352 loss: 17.024320602416992\n",
      "Epoch 352 Validation accuracy: 0.5\n",
      "Epoch 353 loss: 16.99083137512207\n",
      "Epoch 353 Validation accuracy: 0.5\n",
      "Epoch 354 loss: 16.965436935424805\n",
      "Epoch 354 Validation accuracy: 0.5\n",
      "Epoch 355 loss: 16.946870803833008\n",
      "Epoch 355 Validation accuracy: 0.5\n",
      "Epoch 356 loss: 16.932483673095703\n",
      "Epoch 356 Validation accuracy: 0.5\n",
      "Epoch 357 loss: 16.912811279296875\n",
      "Epoch 357 Validation accuracy: 0.5\n",
      "Epoch 358 loss: 16.91278076171875\n",
      "Epoch 358 Validation accuracy: 0.5\n",
      "Epoch 359 loss: 16.910892486572266\n",
      "Epoch 359 Validation accuracy: 0.5\n",
      "Epoch 360 loss: 16.892751693725586\n",
      "Epoch 360 Validation accuracy: 0.5\n",
      "Epoch 361 loss: 16.859865188598633\n",
      "Epoch 361 Validation accuracy: 0.5\n",
      "Epoch 362 loss: 16.86033058166504\n",
      "Epoch 362 Validation accuracy: 0.5\n",
      "Epoch 363 loss: 16.80829620361328\n",
      "Epoch 363 Validation accuracy: 0.5\n",
      "Epoch 364 loss: 16.794227600097656\n",
      "Epoch 364 Validation accuracy: 0.5\n",
      "Epoch 365 loss: 16.846920013427734\n",
      "Epoch 365 Validation accuracy: 0.5\n",
      "Epoch 366 loss: 16.848430633544922\n",
      "Epoch 366 Validation accuracy: 0.5\n",
      "Epoch 367 loss: 16.8135986328125\n",
      "Epoch 367 Validation accuracy: 0.5\n",
      "Epoch 368 loss: 16.729978561401367\n",
      "Epoch 368 Validation accuracy: 0.5\n",
      "Epoch 369 loss: 16.657703399658203\n",
      "Epoch 369 Validation accuracy: 0.5\n",
      "Epoch 370 loss: 16.621173858642578\n",
      "Epoch 370 Validation accuracy: 0.5\n",
      "Epoch 371 loss: 16.679672241210938\n",
      "Epoch 371 Validation accuracy: 0.5\n",
      "Epoch 372 loss: 16.704267501831055\n",
      "Epoch 372 Validation accuracy: 0.5\n",
      "Epoch 373 loss: 16.655868530273438\n",
      "Epoch 373 Validation accuracy: 0.5\n",
      "Epoch 374 loss: 16.617334365844727\n",
      "Epoch 374 Validation accuracy: 0.5\n",
      "Epoch 375 loss: 16.563974380493164\n",
      "Epoch 375 Validation accuracy: 0.5\n",
      "Epoch 376 loss: 16.515806198120117\n",
      "Epoch 376 Validation accuracy: 0.5\n",
      "Epoch 377 loss: 16.485450744628906\n",
      "Epoch 377 Validation accuracy: 0.5\n",
      "Epoch 378 loss: 16.521177291870117\n",
      "Epoch 378 Validation accuracy: 0.5\n",
      "Epoch 379 loss: 16.560949325561523\n",
      "Epoch 379 Validation accuracy: 0.5\n",
      "Epoch 380 loss: 16.47894287109375\n",
      "Epoch 380 Validation accuracy: 0.5\n",
      "Epoch 381 loss: 16.417966842651367\n",
      "Epoch 381 Validation accuracy: 0.5\n",
      "Epoch 382 loss: 16.36986541748047\n",
      "Epoch 382 Validation accuracy: 0.5\n",
      "Epoch 383 loss: 16.344886779785156\n",
      "Epoch 383 Validation accuracy: 0.5\n",
      "Epoch 384 loss: 16.449684143066406\n",
      "Epoch 384 Validation accuracy: 0.5\n",
      "Epoch 385 loss: 16.558286666870117\n",
      "Epoch 385 Validation accuracy: 0.5\n",
      "Epoch 386 loss: 16.764015197753906\n",
      "Epoch 386 Validation accuracy: 0.5\n",
      "Epoch 387 loss: 16.585264205932617\n",
      "Epoch 387 Validation accuracy: 0.5\n",
      "Epoch 388 loss: 16.342666625976562\n",
      "Epoch 388 Validation accuracy: 0.5\n",
      "Epoch 389 loss: 16.285057067871094\n",
      "Epoch 389 Validation accuracy: 0.5\n",
      "Epoch 390 loss: 16.331804275512695\n",
      "Epoch 390 Validation accuracy: 0.5\n",
      "Epoch 391 loss: 16.360849380493164\n",
      "Epoch 391 Validation accuracy: 0.5\n",
      "Epoch 392 loss: 16.298288345336914\n",
      "Epoch 392 Validation accuracy: 0.5\n",
      "Epoch 393 loss: 16.241859436035156\n",
      "Epoch 393 Validation accuracy: 0.5\n",
      "Epoch 394 loss: 16.249521255493164\n",
      "Epoch 394 Validation accuracy: 0.5\n",
      "Epoch 395 loss: 16.276805877685547\n",
      "Epoch 395 Validation accuracy: 0.5\n",
      "Epoch 396 loss: 16.263288497924805\n",
      "Epoch 396 Validation accuracy: 0.5\n",
      "Epoch 397 loss: 16.21145248413086\n",
      "Epoch 397 Validation accuracy: 0.5\n",
      "Epoch 398 loss: 16.163650512695312\n",
      "Epoch 398 Validation accuracy: 0.5\n",
      "Epoch 399 loss: 16.10198211669922\n",
      "Epoch 399 Validation accuracy: 0.5\n",
      "Epoch 400 loss: 16.097929000854492\n",
      "Epoch 400 Validation accuracy: 0.5\n",
      "Epoch 401 loss: 16.110031127929688\n",
      "Epoch 401 Validation accuracy: 0.5\n",
      "Epoch 402 loss: 16.07076644897461\n",
      "Epoch 402 Validation accuracy: 0.5\n",
      "Epoch 403 loss: 16.01443862915039\n",
      "Epoch 403 Validation accuracy: 0.5\n",
      "Epoch 404 loss: 16.02919578552246\n",
      "Epoch 404 Validation accuracy: 0.5\n",
      "Epoch 405 loss: 16.026033401489258\n",
      "Epoch 405 Validation accuracy: 0.5\n",
      "Epoch 406 loss: 15.970462799072266\n",
      "Epoch 406 Validation accuracy: 0.5\n",
      "Epoch 407 loss: 15.983729362487793\n",
      "Epoch 407 Validation accuracy: 0.5\n",
      "Epoch 408 loss: 16.008480072021484\n",
      "Epoch 408 Validation accuracy: 0.5\n",
      "Epoch 409 loss: 16.002965927124023\n",
      "Epoch 409 Validation accuracy: 0.5\n",
      "Epoch 410 loss: 15.95752239227295\n",
      "Epoch 410 Validation accuracy: 0.5\n",
      "Epoch 411 loss: 15.888609886169434\n",
      "Epoch 411 Validation accuracy: 0.5\n",
      "Epoch 412 loss: 15.956046104431152\n",
      "Epoch 412 Validation accuracy: 0.5\n",
      "Epoch 413 loss: 15.972766876220703\n",
      "Epoch 413 Validation accuracy: 0.5\n",
      "Epoch 414 loss: 15.922646522521973\n",
      "Epoch 414 Validation accuracy: 0.5\n",
      "Epoch 415 loss: 15.831913948059082\n",
      "Epoch 415 Validation accuracy: 0.5\n",
      "Epoch 416 loss: 15.869161605834961\n",
      "Epoch 416 Validation accuracy: 0.5\n",
      "Epoch 417 loss: 15.920557975769043\n",
      "Epoch 417 Validation accuracy: 0.5\n",
      "Epoch 418 loss: 15.944183349609375\n",
      "Epoch 418 Validation accuracy: 0.5\n",
      "Epoch 419 loss: 15.915654182434082\n",
      "Epoch 419 Validation accuracy: 0.5\n",
      "Epoch 420 loss: 15.8483304977417\n",
      "Epoch 420 Validation accuracy: 0.5\n",
      "Epoch 421 loss: 15.744543075561523\n",
      "Epoch 421 Validation accuracy: 0.5\n",
      "Epoch 422 loss: 15.802746772766113\n",
      "Epoch 422 Validation accuracy: 0.5\n",
      "Epoch 423 loss: 15.859687805175781\n",
      "Epoch 423 Validation accuracy: 0.5\n",
      "Epoch 424 loss: 15.862791061401367\n",
      "Epoch 424 Validation accuracy: 0.5\n",
      "Epoch 425 loss: 15.791569709777832\n",
      "Epoch 425 Validation accuracy: 0.5\n",
      "Epoch 426 loss: 15.723493576049805\n",
      "Epoch 426 Validation accuracy: 0.5\n",
      "Epoch 427 loss: 15.718402862548828\n",
      "Epoch 427 Validation accuracy: 0.5\n",
      "Epoch 428 loss: 15.718893051147461\n",
      "Epoch 428 Validation accuracy: 0.5\n",
      "Epoch 429 loss: 15.723417282104492\n",
      "Epoch 429 Validation accuracy: 0.5\n",
      "Epoch 430 loss: 15.708714485168457\n",
      "Epoch 430 Validation accuracy: 0.5\n",
      "Epoch 431 loss: 15.744660377502441\n",
      "Epoch 431 Validation accuracy: 0.5\n",
      "Epoch 432 loss: 15.769439697265625\n",
      "Epoch 432 Validation accuracy: 0.5\n",
      "Epoch 433 loss: 15.65803050994873\n",
      "Epoch 433 Validation accuracy: 0.5\n",
      "Epoch 434 loss: 15.521815299987793\n",
      "Epoch 434 Validation accuracy: 0.5\n",
      "Epoch 435 loss: 15.513628959655762\n",
      "Epoch 435 Validation accuracy: 0.5\n",
      "Epoch 436 loss: 15.494930267333984\n",
      "Epoch 436 Validation accuracy: 0.5\n",
      "Epoch 437 loss: 15.504579544067383\n",
      "Epoch 437 Validation accuracy: 0.5\n",
      "Epoch 438 loss: 15.466148376464844\n",
      "Epoch 438 Validation accuracy: 0.5\n",
      "Epoch 439 loss: 15.45976734161377\n",
      "Epoch 439 Validation accuracy: 0.5\n",
      "Epoch 440 loss: 15.459425926208496\n",
      "Epoch 440 Validation accuracy: 0.5\n",
      "Epoch 441 loss: 15.415087699890137\n",
      "Epoch 441 Validation accuracy: 0.5\n",
      "Epoch 442 loss: 15.431467056274414\n",
      "Epoch 442 Validation accuracy: 0.5\n",
      "Epoch 443 loss: 15.41972827911377\n",
      "Epoch 443 Validation accuracy: 0.5\n",
      "Epoch 444 loss: 15.3599853515625\n",
      "Epoch 444 Validation accuracy: 0.5\n",
      "Epoch 445 loss: 15.381430625915527\n",
      "Epoch 445 Validation accuracy: 0.5\n",
      "Epoch 446 loss: 15.405269622802734\n",
      "Epoch 446 Validation accuracy: 0.5\n",
      "Epoch 447 loss: 15.40130615234375\n",
      "Epoch 447 Validation accuracy: 0.5\n",
      "Epoch 448 loss: 15.368307113647461\n",
      "Epoch 448 Validation accuracy: 0.5\n",
      "Epoch 449 loss: 15.312417030334473\n",
      "Epoch 449 Validation accuracy: 0.5\n",
      "Epoch 450 loss: 15.33791732788086\n",
      "Epoch 450 Validation accuracy: 0.5\n",
      "Epoch 451 loss: 15.369656562805176\n",
      "Epoch 451 Validation accuracy: 0.5\n",
      "Epoch 452 loss: 15.313040733337402\n",
      "Epoch 452 Validation accuracy: 0.5\n",
      "Epoch 453 loss: 15.282257080078125\n",
      "Epoch 453 Validation accuracy: 0.5\n",
      "Epoch 454 loss: 15.29808521270752\n",
      "Epoch 454 Validation accuracy: 0.5\n",
      "Epoch 455 loss: 15.262235641479492\n",
      "Epoch 455 Validation accuracy: 0.5\n",
      "Epoch 456 loss: 15.218486785888672\n",
      "Epoch 456 Validation accuracy: 0.5\n",
      "Epoch 457 loss: 15.2057466506958\n",
      "Epoch 457 Validation accuracy: 0.5\n",
      "Epoch 458 loss: 15.141533851623535\n",
      "Epoch 458 Validation accuracy: 0.5\n",
      "Epoch 459 loss: 15.1051607131958\n",
      "Epoch 459 Validation accuracy: 0.5\n",
      "Epoch 460 loss: 15.10201358795166\n",
      "Epoch 460 Validation accuracy: 0.5\n",
      "Epoch 461 loss: 15.074950218200684\n",
      "Epoch 461 Validation accuracy: 0.5\n",
      "Epoch 462 loss: 15.101686477661133\n",
      "Epoch 462 Validation accuracy: 0.5\n",
      "Epoch 463 loss: 15.124187469482422\n",
      "Epoch 463 Validation accuracy: 0.5\n",
      "Epoch 464 loss: 15.123106956481934\n",
      "Epoch 464 Validation accuracy: 0.5\n",
      "Epoch 465 loss: 15.162192344665527\n",
      "Epoch 465 Validation accuracy: 0.5\n",
      "Epoch 466 loss: 15.228984832763672\n",
      "Epoch 466 Validation accuracy: 0.5\n",
      "Epoch 467 loss: 15.158577919006348\n",
      "Epoch 467 Validation accuracy: 0.5\n",
      "Epoch 468 loss: 15.19609546661377\n",
      "Epoch 468 Validation accuracy: 0.5\n",
      "Epoch 469 loss: 15.160114288330078\n",
      "Epoch 469 Validation accuracy: 0.5\n",
      "Epoch 470 loss: 15.087261199951172\n",
      "Epoch 470 Validation accuracy: 0.5\n",
      "Epoch 471 loss: 14.96879768371582\n",
      "Epoch 471 Validation accuracy: 0.5\n",
      "Epoch 472 loss: 14.92802619934082\n",
      "Epoch 472 Validation accuracy: 0.5\n",
      "Epoch 473 loss: 14.968253135681152\n",
      "Epoch 473 Validation accuracy: 0.5\n",
      "Epoch 474 loss: 14.986725807189941\n",
      "Epoch 474 Validation accuracy: 0.5\n",
      "Epoch 475 loss: 15.062368392944336\n",
      "Epoch 475 Validation accuracy: 0.5\n",
      "Epoch 476 loss: 15.099820137023926\n",
      "Epoch 476 Validation accuracy: 0.5\n",
      "Epoch 477 loss: 15.082950592041016\n",
      "Epoch 477 Validation accuracy: 0.5\n",
      "Epoch 478 loss: 14.984455108642578\n",
      "Epoch 478 Validation accuracy: 0.5\n",
      "Epoch 479 loss: 14.891192436218262\n",
      "Epoch 479 Validation accuracy: 0.5\n",
      "Epoch 480 loss: 14.787556648254395\n",
      "Epoch 480 Validation accuracy: 0.5\n",
      "Epoch 481 loss: 14.836790084838867\n",
      "Epoch 481 Validation accuracy: 0.5\n",
      "Epoch 482 loss: 14.86919116973877\n",
      "Epoch 482 Validation accuracy: 0.5\n",
      "Epoch 483 loss: 14.856099128723145\n",
      "Epoch 483 Validation accuracy: 0.5\n",
      "Epoch 484 loss: 14.785355567932129\n",
      "Epoch 484 Validation accuracy: 0.5\n",
      "Epoch 485 loss: 14.83121395111084\n",
      "Epoch 485 Validation accuracy: 0.5\n",
      "Epoch 486 loss: 14.832079887390137\n",
      "Epoch 486 Validation accuracy: 0.5\n",
      "Epoch 487 loss: 14.769269943237305\n",
      "Epoch 487 Validation accuracy: 0.5\n",
      "Epoch 488 loss: 14.683329582214355\n",
      "Epoch 488 Validation accuracy: 0.5\n",
      "Epoch 489 loss: 14.753135681152344\n",
      "Epoch 489 Validation accuracy: 0.5\n",
      "Epoch 490 loss: 14.84272575378418\n",
      "Epoch 490 Validation accuracy: 0.5\n",
      "Epoch 491 loss: 14.868659973144531\n",
      "Epoch 491 Validation accuracy: 0.5\n",
      "Epoch 492 loss: 14.7947359085083\n",
      "Epoch 492 Validation accuracy: 0.5\n",
      "Epoch 493 loss: 14.678095817565918\n",
      "Epoch 493 Validation accuracy: 0.5\n",
      "Epoch 494 loss: 14.682825088500977\n",
      "Epoch 494 Validation accuracy: 0.5\n",
      "Epoch 495 loss: 14.704837799072266\n",
      "Epoch 495 Validation accuracy: 0.5\n",
      "Epoch 496 loss: 14.674065589904785\n",
      "Epoch 496 Validation accuracy: 0.5\n",
      "Epoch 497 loss: 14.598418235778809\n",
      "Epoch 497 Validation accuracy: 0.5\n",
      "Epoch 498 loss: 14.58089542388916\n",
      "Epoch 498 Validation accuracy: 0.5\n",
      "Epoch 499 loss: 14.638450622558594\n",
      "Epoch 499 Validation accuracy: 0.5\n",
      "Test accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for x_1, incidence_1, y in zip(x_1_train, incidence_1_train, y_train):\n",
    "        output = model(x_1.float(), incidence_1.float())\n",
    "        loss += crit(output, torch.tensor([y]).float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch} loss: {loss.item()}\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        for x_1, incidence_1, y in zip(x_1_val, incidence_1_val, y_val):\n",
    "            output = model(x_1.float(), incidence_1.float())\n",
    "            pred = output > 0.5\n",
    "            if pred == y:\n",
    "                correct += 1\n",
    "        print(f\"Epoch {epoch} Validation accuracy: {correct / len(y_val)}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for x_1, incidence_1, y in zip(x_1_test, incidence_1_test, y_test):\n",
    "        output = model(x_1.float(), incidence_1.float())\n",
    "        pred = output > 0.5\n",
    "        if pred == y:\n",
    "            correct += 1\n",
    "    print(f\"Test accuracy: {correct / len(y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
