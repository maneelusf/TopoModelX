{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)\n",
    "\n",
    "In this notebook, we will create and train a Simplicial Neural Network for Homology Localization, as proposed in the paper by [Alexandros D. Keros et. al : Dist2Cycle: A Simplicial Neural Network for Homology Localization(2022)](https://ojs.aaai.org/index.php/AAAI/article/view/20673/20432). \n",
    "\n",
    "We train the model to perform binary node classification using the KarateClub benchmark dataset. \n",
    "\n",
    "The equations of one layer of this neural network are given by:\n",
    "\n",
    "ðŸŸ¥ $\\quad m^{(1 \\rightarrow 1)}\\_{y \\rightarrow x}  = (A \\odot (I + L\\downarrow)^+{xy}) \\cdot h_{y}^{t,(1)}\\cdot \\Theta^t$\n",
    "\n",
    "ðŸŸ§ $\\quad m_x^{(1 \\rightarrow 1)}  = \\sum_{y \\in \\mathcal{L}\\_\\downarrow(x)} m_{y \\rightarrow x}^{(1 \\rightarrow 1)}$\n",
    "\n",
    "ðŸŸ© $\\quad m_x^{(1)}  = m^{(1 \\rightarrow 1)}_x$\n",
    "\n",
    "ðŸŸ¦ $\\quad h_x^{t+1,(1)} = \\sigma(m_{x}^{(1)})$\n",
    "\n",
    "\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import toponetx.datasets.graph as graph\n",
    "\n",
    "from topomodelx.nn.simplicial.dist2cycle import Dist2Cycle\n",
    "import numpy.linalg as npla"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import dataset ##\n",
    "\n",
    "The first step is to import the Karate Club (https://www.jstor.org/stable/3629752) dataset. This is a singular graph with 34 nodes that belong to two different social groups. We will use these groups for the task of node-level binary classification.\n",
    "\n",
    "We must first lift our graph dataset into the simplicial complex domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplicial Complex with shape (34, 78, 45, 11, 2) and dimension 4\n"
     ]
    }
   ],
   "source": [
    "dataset = graph.karate_club(complex_type=\"simplicial\")\n",
    "print(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neighborhood structures. ##\n",
    "\n",
    "Now we retrieve the neighborhood structures (i.e. their representative matrices) that we will use to send messges on the domain. In this case, we need the boundary matrix (or incidence matrix) $B_1$ and the adjacency matrix $A_{\\uparrow,0}$ on the nodes. For a santiy check, we show that the shape of the $B_1 = n_\\text{nodes} \\times n_\\text{edges}$ and $A_{\\uparrow,0} = n_\\text{nodes} \\times n_\\text{nodes}$. We also convert the neighborhood structures to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The incidence matrix B1 has shape: torch.Size([34, 78]).\n",
      "The adjacency matrix A0 has shape: torch.Size([34, 34]).\n"
     ]
    }
   ],
   "source": [
    "incidence_1 = dataset.incidence_matrix(rank=1)\n",
    "adjacency_0 = dataset.adjacency_matrix(rank=0)\n",
    "\n",
    "incidence_1 = torch.from_numpy(incidence_1.todense()).to_sparse()\n",
    "adjacency_0 = torch.from_numpy(adjacency_0.todense()).to_sparse()\n",
    "\n",
    "print(f\"The incidence matrix B1 has shape: {incidence_1.shape}.\")\n",
    "print(f\"The adjacency matrix A0 has shape: {adjacency_0.shape}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import signal ##\n",
    "\n",
    "Since our task will be node classification, we must retrieve an input signal on the nodes. The signal will have shape $n_\\text{nodes} \\times$ in_channels, where in_channels is the dimension of each cell's feature. Here, we have in_channels = channels_nodes $ = 34$. This is because the Karate dataset encodes the identity of each of the 34 nodes as a one hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "x_0 = []\n",
    "for _, v in dataset.get_simplex_attributes(\"node_feat\").items():\n",
    "    x_0.append(v)\n",
    "x_0 = torch.tensor(np.stack(x_0))\n",
    "channels_nodes = x_0.shape[-1]\n",
    "print(channels_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34 nodes with features of dimension 2.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {x_0.shape[0]} nodes with features of dimension {x_0.shape[1]}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load edge features, this is how we would do it (note that we will not use these features for this model, and this serves simply as a demonstration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = []\n",
    "for k, v in dataset.get_simplex_attributes(\"edge_feat\").items():\n",
    "    x_1.append(v)\n",
    "x_1 = np.stack(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 78 edges with features of dimension 2.\n",
      "[[ 3.95621406e-04 -1.03015481e-02]\n",
      " [-6.55616671e-02  7.38313869e-02]\n",
      " [-2.09062062e-02  1.19224805e-02]\n",
      " [-3.44589353e-08  3.67354822e-08]\n",
      " [-4.93600965e-08  4.88985457e-08]\n",
      " [-4.00468707e-08  3.69924322e-08]\n",
      " [-2.15180665e-02  1.88630801e-02]\n",
      " [-1.06691465e-01  7.89363235e-02]\n",
      " [-3.53902578e-08  3.74956741e-08]\n",
      " [ 1.30385160e-08 -1.06426796e-08]\n",
      " [-1.04531134e-02  5.96124958e-03]\n",
      " [-2.83000078e-02 -1.68193001e-02]\n",
      " [ 1.97816640e-04 -5.15078427e-03]\n",
      " [ 1.29186928e-01 -8.58572349e-02]\n",
      " [ 1.97815709e-04 -5.15078334e-03]\n",
      " [ 1.23452507e-01 -6.62350655e-02]\n",
      " [-6.59572855e-02  8.41329321e-02]\n",
      " [-2.13018209e-02  2.22240202e-02]\n",
      " [-2.19136793e-02  2.91646216e-02]\n",
      " [-2.86956131e-02 -6.51777070e-03]\n",
      " [-1.97816407e-04  5.15078008e-03]\n",
      " [ 1.28791258e-01 -7.55556449e-02]\n",
      " [-1.97811052e-04  5.15077310e-03]\n",
      " [ 9.86839272e-03 -7.40512535e-02]\n",
      " [ 4.46554571e-02 -6.19089082e-02]\n",
      " [ 4.40435968e-02 -5.49683049e-02]\n",
      " [-4.11297679e-02  5.10491943e-03]\n",
      " [ 1.19836420e-01 -9.60656479e-02]\n",
      " [ 3.72616611e-02 -9.06506926e-02]\n",
      " [ 9.72085670e-02  6.38227835e-02]\n",
      " [-3.49416107e-01  3.72791708e-01]\n",
      " [-8.39787647e-02  1.98384672e-02]\n",
      " [-6.11861644e-04  6.94060465e-03]\n",
      " [ 1.04530957e-02 -5.96123515e-03]\n",
      " [-7.39379786e-03 -2.87417863e-02]\n",
      " [-1.15833245e-08  8.14344503e-09]\n",
      " [ 4.92769647e-09  2.33998543e-10]\n",
      " [ 3.35523831e-09 -3.98281214e-10]\n",
      " [ 3.11410986e-09 -8.59467075e-09]\n",
      " [-1.74622983e-08  2.01718624e-08]\n",
      " [-2.54367478e-08  2.39908786e-08]\n",
      " [-3.94224003e-02  3.95231210e-02]\n",
      " [-4.28489819e-02  1.47335352e-02]\n",
      " [-6.55498430e-02  2.97845788e-02]\n",
      " [ 1.19836412e-01 -9.60656404e-02]\n",
      " [-2.71277428e-02 -1.42729551e-01]\n",
      " [ 1.13504194e-02 -7.52551015e-03]\n",
      " [-1.13504231e-02  7.52551202e-03]\n",
      " [ 1.13504184e-02 -7.52551062e-03]\n",
      " [-1.13504231e-02  7.52551202e-03]\n",
      " [ 1.13504194e-02 -7.52551109e-03]\n",
      " [-1.13504231e-02  7.52551202e-03]\n",
      " [ 2.57978112e-01 -1.61412820e-01]\n",
      " [ 1.13504212e-02 -7.52551295e-03]\n",
      " [-1.13504231e-02  7.52551714e-03]\n",
      " [ 1.13504147e-02 -7.52550783e-03]\n",
      " [-1.13504231e-02  7.52551714e-03]\n",
      " [-1.51450206e-02  5.78382574e-02]\n",
      " [-2.00048350e-02 -1.35983443e-02]\n",
      " [ 8.05518497e-03 -1.08499276e-02]\n",
      " [ 2.48977523e-02 -2.42205039e-02]\n",
      " [ 2.19691545e-03 -9.16947890e-03]\n",
      " [ 2.33823359e-02 -4.01422847e-03]\n",
      " [-5.50019667e-02 -4.57955822e-02]\n",
      " [ 3.16196270e-02  4.98098060e-02]\n",
      " [ 8.23729578e-03  5.38240373e-02]\n",
      " [ 2.92913034e-03 -8.40216933e-04]\n",
      " [-2.92913616e-03  8.40231252e-04]\n",
      " [ 2.22017616e-02  4.42885561e-03]\n",
      " [-1.67888165e-01  1.38626724e-01]\n",
      " [-1.81527972e-01  2.34165013e-01]\n",
      " [ 1.68425720e-02 -1.33705791e-02]\n",
      " [-5.85826486e-03  1.68044865e-03]\n",
      " [-3.42658581e-03 -2.47895792e-02]\n",
      " [-2.61274278e-02 -9.73856449e-03]\n",
      " [ 9.06107482e-03  8.04872215e-02]\n",
      " [-1.36397779e-02  9.55382437e-02]\n",
      " [-2.27008536e-02  1.50510371e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {x_1.shape[0]} edges with features of dimension {x_1.shape[1]}.\")\n",
    "print(x_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for face features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = []\n",
    "for k, v in dataset.get_simplex_attributes(\"face_feat\").items():\n",
    "    x_2.append(v)\n",
    "x_2 = np.stack(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 faces with features of dimension 2.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {x_2.shape[0]} faces with features of dimension {x_2.shape[1]}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define binary labels\n",
    "We retrieve the labels associated to the nodes of each input simplex. In the KarateClub dataset, two social groups emerge. So we assign binary labels to the nodes indicating of which group they are a part.\n",
    "\n",
    "We convert the binary labels into one-hot encoder form, and keep the first four nodes' true labels for the purpose of testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78,)\n",
      "torch.Size([30, 2])\n"
     ]
    }
   ],
   "source": [
    "y = np.array(\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ]\n",
    ")\n",
    "y = np.append(y, y)\n",
    "y = np.append(y, [1, 1, 1, 1, 1, 1, 0, 0, 0, 1])\n",
    "\n",
    "print(y.shape)\n",
    "y_true = np.zeros((78, 2))\n",
    "y_true[:, 0] = y\n",
    "y_true[:, 1] = 1 - y\n",
    "y_test = y_true[-4:]\n",
    "y_train = y_true[:30]\n",
    "\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "(78, 78)\n",
      "(78, 78)\n",
      "(78, 2)\n",
      "(78, 78)\n",
      "tensor(indices=tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "                         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,\n",
      "                         2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  4,  4,  4,  4,\n",
      "                         5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  7,  7,  8,  8,\n",
      "                         8,  8, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 13, 13,\n",
      "                        14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17,\n",
      "                        17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19,\n",
      "                        19, 19, 20, 20, 21, 21, 22, 22, 24, 24, 24, 24, 24, 24,\n",
      "                        24, 24, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 28, 28,\n",
      "                        28, 28, 28, 28, 31, 31, 32, 32, 32, 32, 32, 32, 33, 33,\n",
      "                        34, 34, 34, 34, 34, 34, 35, 35, 36, 36, 37, 37, 37, 37,\n",
      "                        38, 38, 39, 39, 40, 40, 41, 41, 41, 41, 42, 42, 42, 42,\n",
      "                        42, 42, 43, 43, 43, 43, 46, 46, 47, 47, 48, 48, 49, 49,\n",
      "                        50, 50, 51, 51, 53, 53, 54, 54, 55, 55, 56, 56, 58, 58,\n",
      "                        59, 59, 59, 59, 60, 60, 60, 60, 61, 61, 61, 61, 61, 61,\n",
      "                        62, 62, 64, 64, 65, 65, 66, 66, 67, 67, 68, 68, 69, 69,\n",
      "                        70, 70, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 73, 73,\n",
      "                        73, 73, 74, 74, 74, 74, 75, 75, 76, 76, 76, 76, 77, 77,\n",
      "                        77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77,\n",
      "                        77, 77, 77, 77],\n",
      "                       [ 1,  2,  6, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22,\n",
      "                         0,  2,  6,  7, 11, 16, 24, 25, 26, 28,  0,  1,  6, 10,\n",
      "                        11, 17, 24, 32, 33, 34,  5,  8, 35, 36,  5,  8, 37, 38,\n",
      "                         3,  4, 35, 37,  0,  1,  2, 18, 25, 32,  1, 26,  3,  4,\n",
      "                        36, 38,  2, 33,  0,  1,  2, 19, 28, 34,  0, 20,  0, 21,\n",
      "                         0, 22,  0,  1, 17, 18, 19, 24, 25, 28,  0,  2, 16, 18,\n",
      "                        19, 24, 32, 34,  0,  6, 16, 17, 25, 32,  0, 11, 16, 17,\n",
      "                        28, 34,  0, 12,  0, 13,  0, 14,  1,  2, 16, 17, 25, 28,\n",
      "                        32, 34,  1,  6, 16, 18, 24, 32,  1,  7, 31, 42,  1, 11,\n",
      "                        16, 19, 24, 34, 26, 42,  2,  6, 17, 18, 24, 25,  2, 10,\n",
      "                         2, 11, 17, 19, 24, 28,  3,  5,  3,  8,  4,  5, 39, 40,\n",
      "                         4,  8, 37, 40, 37, 39, 42, 43, 73, 74, 26, 31, 41, 43,\n",
      "                        73, 77, 41, 42, 74, 77, 47, 77, 46, 77, 49, 77, 48, 77,\n",
      "                        51, 77, 50, 77, 54, 77, 53, 77, 56, 77, 55, 77, 61, 68,\n",
      "                        60, 61, 71, 72, 59, 61, 71, 77, 58, 59, 60, 68, 72, 77,\n",
      "                        64, 65, 62, 65, 62, 64, 67, 72, 66, 72, 58, 61, 70, 76,\n",
      "                        69, 76, 59, 60, 72, 77, 59, 61, 66, 67, 71, 77, 41, 42,\n",
      "                        74, 77, 41, 43, 73, 77, 76, 77, 69, 70, 75, 77, 42, 43,\n",
      "                        46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 60, 61, 71, 72,\n",
      "                        73, 74, 75, 76]]),\n",
      "       values=tensor([-0.0650, -0.0663, -0.0701, -0.0685, -0.0731, -0.0699,\n",
      "                      -0.0731,  0.0971,  0.0959,  0.0920,  0.0937,  0.0891,\n",
      "                       0.0923,  0.0891, -0.0650, -0.0687, -0.0721, -0.0754,\n",
      "                      -0.0725, -0.0968,  0.0930,  0.0897,  0.0864,  0.0892,\n",
      "                      -0.0663, -0.0687, -0.0789, -0.0864, -0.0749, -0.1380,\n",
      "                      -0.1356,  0.1255,  0.1179,  0.1294, -0.1009, -0.1080,\n",
      "                       0.2140,  0.2069, -0.1106, -0.1009,  0.1724,  0.1821,\n",
      "                      -0.1009, -0.1106, -0.1821, -0.1724, -0.0701, -0.0721,\n",
      "                      -0.0789, -0.1851, -0.1831, -0.1763, -0.0754, -0.1628,\n",
      "                      -0.1080, -0.1009, -0.2069, -0.2140, -0.0864, -0.2927,\n",
      "                      -0.0685, -0.0725, -0.0749, -0.1560, -0.1519, -0.1495,\n",
      "                      -0.0731, -0.3018, -0.0699, -0.2309, -0.0731, -0.3018,\n",
      "                       0.0971, -0.0968, -0.0996, -0.0992, -0.1012,  0.0943,\n",
      "                       0.0948,  0.0927,  0.0959, -0.1380, -0.0996, -0.1046,\n",
      "                      -0.1023, -0.1343,  0.1293,  0.1316,  0.0920, -0.1851,\n",
      "                      -0.0992, -0.1046, -0.1780, -0.1725,  0.0937, -0.1560,\n",
      "                      -0.1012, -0.1023, -0.1484, -0.1473,  0.0891, -0.3018,\n",
      "                       0.0923, -0.2309,  0.0891, -0.3018,  0.0930, -0.1356,\n",
      "                       0.0943, -0.1343, -0.0998, -0.0954,  0.1288,  0.1332,\n",
      "                       0.0897, -0.1831,  0.0948, -0.1780, -0.0998, -0.1730,\n",
      "                       0.0864, -0.1628, -0.1006,  0.1487,  0.0892, -0.1519,\n",
      "                       0.0927, -0.1484, -0.0954, -0.1457, -0.1006, -0.0891,\n",
      "                       0.1255, -0.1763,  0.1293, -0.1725,  0.1288, -0.1730,\n",
      "                       0.1179, -0.2927,  0.1294, -0.1495,  0.1316, -0.1473,\n",
      "                       0.1332, -0.1457,  0.2140, -0.1821,  0.2069, -0.2069,\n",
      "                       0.1724, -0.1724, -0.1724,  0.1724,  0.1821, -0.2140,\n",
      "                      -0.1724, -0.2678,  0.1724, -0.2678, -0.1429, -0.1426,\n",
      "                       0.1734,  0.1738,  0.1487, -0.0891, -0.1429, -0.1654,\n",
      "                      -0.0948,  0.0724, -0.1426, -0.1654, -0.0804, -0.0576,\n",
      "                      -0.3090,  0.0693, -0.3090, -0.0607, -0.3090,  0.0693,\n",
      "                      -0.3090, -0.0607, -0.3090,  0.0693, -0.3090, -0.0607,\n",
      "                      -0.3090,  0.0693, -0.3090, -0.0607, -0.3090,  0.0693,\n",
      "                      -0.3090, -0.0607, -0.1474,  0.1836, -0.1511, -0.1518,\n",
      "                       0.1812,  0.1804, -0.1511, -0.1724, -0.0960,  0.0746,\n",
      "                      -0.1474, -0.1518, -0.1724, -0.0803, -0.0759, -0.0553,\n",
      "                      -0.2077,  0.2056, -0.2077, -0.1475,  0.2056, -0.1475,\n",
      "                      -0.2813,  0.1545, -0.2813, -0.1019,  0.1836, -0.0803,\n",
      "                      -0.2206,  0.1293, -0.2206, -0.0819,  0.1812, -0.0960,\n",
      "                      -0.2017,  0.0754,  0.1804, -0.0759,  0.1545, -0.1019,\n",
      "                      -0.2017, -0.0546,  0.1734, -0.0948, -0.1962,  0.0720,\n",
      "                       0.1738, -0.0804, -0.1962, -0.0580, -0.1575,  0.0762,\n",
      "                       0.1293, -0.0819, -0.1575, -0.0537,  0.0724, -0.0576,\n",
      "                       0.0693, -0.0607,  0.0693, -0.0607,  0.0693, -0.0607,\n",
      "                       0.0693, -0.0607,  0.0693, -0.0607,  0.0746, -0.0553,\n",
      "                       0.0754, -0.0546,  0.0720, -0.0580,  0.0762, -0.0537]),\n",
      "       size=(78, 78), nnz=270, layout=torch.sparse_coo)\n",
      "[[ 3.95621406e-04 -1.03015481e-02]\n",
      " [-6.55616671e-02  7.38313869e-02]\n",
      " [-2.09062062e-02  1.19224805e-02]\n",
      " [-3.44589353e-08  3.67354822e-08]\n",
      " [-4.93600965e-08  4.88985457e-08]\n",
      " [-4.00468707e-08  3.69924322e-08]\n",
      " [-2.15180665e-02  1.88630801e-02]\n",
      " [-1.06691465e-01  7.89363235e-02]\n",
      " [-3.53902578e-08  3.74956741e-08]\n",
      " [ 1.30385160e-08 -1.06426796e-08]\n",
      " [-1.04531134e-02  5.96124958e-03]\n",
      " [-2.83000078e-02 -1.68193001e-02]\n",
      " [ 1.97816640e-04 -5.15078427e-03]\n",
      " [ 1.29186928e-01 -8.58572349e-02]\n",
      " [ 1.97815709e-04 -5.15078334e-03]\n",
      " [ 1.23452507e-01 -6.62350655e-02]\n",
      " [-6.59572855e-02  8.41329321e-02]\n",
      " [-2.13018209e-02  2.22240202e-02]\n",
      " [-2.19136793e-02  2.91646216e-02]\n",
      " [-2.86956131e-02 -6.51777070e-03]\n",
      " [-1.97816407e-04  5.15078008e-03]\n",
      " [ 1.28791258e-01 -7.55556449e-02]\n",
      " [-1.97811052e-04  5.15077310e-03]\n",
      " [ 9.86839272e-03 -7.40512535e-02]\n",
      " [ 4.46554571e-02 -6.19089082e-02]\n",
      " [ 4.40435968e-02 -5.49683049e-02]\n",
      " [-4.11297679e-02  5.10491943e-03]\n",
      " [ 1.19836420e-01 -9.60656479e-02]\n",
      " [ 3.72616611e-02 -9.06506926e-02]\n",
      " [ 9.72085670e-02  6.38227835e-02]\n",
      " [-3.49416107e-01  3.72791708e-01]\n",
      " [-8.39787647e-02  1.98384672e-02]\n",
      " [-6.11861644e-04  6.94060465e-03]\n",
      " [ 1.04530957e-02 -5.96123515e-03]\n",
      " [-7.39379786e-03 -2.87417863e-02]\n",
      " [-1.15833245e-08  8.14344503e-09]\n",
      " [ 4.92769647e-09  2.33998543e-10]\n",
      " [ 3.35523831e-09 -3.98281214e-10]\n",
      " [ 3.11410986e-09 -8.59467075e-09]\n",
      " [-1.74622983e-08  2.01718624e-08]\n",
      " [-2.54367478e-08  2.39908786e-08]\n",
      " [-3.94224003e-02  3.95231210e-02]\n",
      " [-4.28489819e-02  1.47335352e-02]\n",
      " [-6.55498430e-02  2.97845788e-02]\n",
      " [ 1.19836412e-01 -9.60656404e-02]\n",
      " [-2.71277428e-02 -1.42729551e-01]\n",
      " [ 1.13504194e-02 -7.52551015e-03]\n",
      " [-1.13504231e-02  7.52551202e-03]\n",
      " [ 1.13504184e-02 -7.52551062e-03]\n",
      " [-1.13504231e-02  7.52551202e-03]\n",
      " [ 1.13504194e-02 -7.52551109e-03]\n",
      " [-1.13504231e-02  7.52551202e-03]\n",
      " [ 2.57978112e-01 -1.61412820e-01]\n",
      " [ 1.13504212e-02 -7.52551295e-03]\n",
      " [-1.13504231e-02  7.52551714e-03]\n",
      " [ 1.13504147e-02 -7.52550783e-03]\n",
      " [-1.13504231e-02  7.52551714e-03]\n",
      " [-1.51450206e-02  5.78382574e-02]\n",
      " [-2.00048350e-02 -1.35983443e-02]\n",
      " [ 8.05518497e-03 -1.08499276e-02]\n",
      " [ 2.48977523e-02 -2.42205039e-02]\n",
      " [ 2.19691545e-03 -9.16947890e-03]\n",
      " [ 2.33823359e-02 -4.01422847e-03]\n",
      " [-5.50019667e-02 -4.57955822e-02]\n",
      " [ 3.16196270e-02  4.98098060e-02]\n",
      " [ 8.23729578e-03  5.38240373e-02]\n",
      " [ 2.92913034e-03 -8.40216933e-04]\n",
      " [-2.92913616e-03  8.40231252e-04]\n",
      " [ 2.22017616e-02  4.42885561e-03]\n",
      " [-1.67888165e-01  1.38626724e-01]\n",
      " [-1.81527972e-01  2.34165013e-01]\n",
      " [ 1.68425720e-02 -1.33705791e-02]\n",
      " [-5.85826486e-03  1.68044865e-03]\n",
      " [-3.42658581e-03 -2.47895792e-02]\n",
      " [-2.61274278e-02 -9.73856449e-03]\n",
      " [ 9.06107482e-03  8.04872215e-02]\n",
      " [-1.36397779e-02  9.55382437e-02]\n",
      " [-2.27008536e-02  1.50510371e-02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkarri/anaconda3/envs/tmx/lib/python3.11/site-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "test = dataset.get_simplex_attributes(\"edge_feat\")\n",
    "\n",
    "ld = dataset.down_laplacian_matrix(rank=1).todense()\n",
    "A = dataset.adjacency_matrix(rank=1).todense()\n",
    "L_tilde_pinv = npla.pinv(ld + np.eye(ld.shape[0]))  # test inverse\n",
    "channels_nodes = 78  # L_tilde_pinv.shape[-1]\n",
    "print(channels_nodes)\n",
    "print(np.array(A).shape)\n",
    "print(np.array(ld).shape)\n",
    "print(x_1.shape)  # edge features\n",
    "print(L_tilde_pinv.shape)\n",
    "\n",
    "adjacency = torch.from_numpy(A).float().to_sparse()\n",
    "Linv = torch.from_numpy(L_tilde_pinv).float().to_sparse()\n",
    "\n",
    "res = adjacency * Linv\n",
    "print(res)\n",
    "print(x_1)\n",
    "\n",
    "x_1e = res.to_sparse()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the Dist2Cycle class, we create a neural network with stacked layers. A linear layer at the end produces an output, so we can compare with our binary labels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model with our pre-made neighborhood structures and specify an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dist2Cycle(\n",
    "    channels=channels_nodes,\n",
    "    n_layers=10,\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell performs the training, looping over the network for a low number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 0.7255 Train_acc: 0.4333\n",
      "Epoch: 2 loss: 0.6995 Train_acc: 0.5667\n",
      "Test_acc: 0.2500\n",
      "Epoch: 3 loss: 0.6883 Train_acc: 0.5667\n",
      "Epoch: 4 loss: 0.6752 Train_acc: 0.5667\n",
      "Test_acc: 0.2500\n",
      "Epoch: 5 loss: 0.6580 Train_acc: 0.5667\n",
      "Epoch: 6 loss: 0.6436 Train_acc: 0.5667\n",
      "Test_acc: 0.0000\n",
      "Epoch: 7 loss: 0.6356 Train_acc: 0.6000\n",
      "Epoch: 8 loss: 0.6294 Train_acc: 0.4000\n",
      "Test_acc: 0.2500\n",
      "Epoch: 9 loss: 0.6210 Train_acc: 0.3667\n",
      "Epoch: 10 loss: 0.6123 Train_acc: 0.6000\n",
      "Test_acc: 0.0000\n",
      "Epoch: 11 loss: 0.6056 Train_acc: 0.6000\n",
      "Epoch: 12 loss: 0.6008 Train_acc: 0.6000\n",
      "Test_acc: 0.0000\n",
      "Epoch: 13 loss: 0.5964 Train_acc: 0.6000\n",
      "Epoch: 14 loss: 0.5916 Train_acc: 0.6000\n",
      "Test_acc: 0.0000\n",
      "Epoch: 15 loss: 0.5863 Train_acc: 0.6000\n",
      "Epoch: 16 loss: 0.5810 Train_acc: 0.6000\n",
      "Test_acc: 0.7500\n",
      "Epoch: 17 loss: 0.5764 Train_acc: 0.5333\n",
      "Epoch: 18 loss: 0.5727 Train_acc: 0.4000\n",
      "Test_acc: 0.7500\n",
      "Epoch: 19 loss: 0.5696 Train_acc: 0.4000\n",
      "Epoch: 20 loss: 0.5663 Train_acc: 0.4000\n",
      "Test_acc: 0.7500\n",
      "Epoch: 21 loss: 0.5628 Train_acc: 0.4000\n",
      "Epoch: 22 loss: 0.5595 Train_acc: 0.4000\n",
      "Test_acc: 0.7500\n",
      "Epoch: 23 loss: 0.5566 Train_acc: 0.4000\n",
      "Epoch: 24 loss: 0.5542 Train_acc: 0.4000\n",
      "Test_acc: 0.7500\n",
      "Epoch: 25 loss: 0.5520 Train_acc: 0.4000\n",
      "Epoch: 26 loss: 0.5498 Train_acc: 0.4000\n",
      "Test_acc: 0.7500\n",
      "Epoch: 27 loss: 0.5474 Train_acc: 0.4000\n",
      "Epoch: 28 loss: 0.5452 Train_acc: 0.4000\n",
      "Test_acc: 0.7500\n",
      "Epoch: 29 loss: 0.5432 Train_acc: 0.4000\n",
      "Epoch: 30 loss: 0.5414 Train_acc: 0.4000\n",
      "Test_acc: 0.7500\n",
      "Epoch: 31 loss: 0.5398 Train_acc: 0.4333\n",
      "Epoch: 32 loss: 0.5381 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 33 loss: 0.5364 Train_acc: 0.4333\n",
      "Epoch: 34 loss: 0.5348 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 35 loss: 0.5333 Train_acc: 0.4333\n",
      "Epoch: 36 loss: 0.5320 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 37 loss: 0.5309 Train_acc: 0.4333\n",
      "Epoch: 38 loss: 0.5297 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 39 loss: 0.5285 Train_acc: 0.4333\n",
      "Epoch: 40 loss: 0.5275 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 41 loss: 0.5264 Train_acc: 0.4333\n",
      "Epoch: 42 loss: 0.5255 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 43 loss: 0.5247 Train_acc: 0.4333\n",
      "Epoch: 44 loss: 0.5239 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 45 loss: 0.5231 Train_acc: 0.4333\n",
      "Epoch: 46 loss: 0.5224 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 47 loss: 0.5217 Train_acc: 0.4333\n",
      "Epoch: 48 loss: 0.5211 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 49 loss: 0.5205 Train_acc: 0.4333\n",
      "Epoch: 50 loss: 0.5199 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 51 loss: 0.5194 Train_acc: 0.4333\n",
      "Epoch: 52 loss: 0.5189 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 53 loss: 0.5184 Train_acc: 0.4333\n",
      "Epoch: 54 loss: 0.5179 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 55 loss: 0.5175 Train_acc: 0.4333\n",
      "Epoch: 56 loss: 0.5171 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 57 loss: 0.5167 Train_acc: 0.4333\n",
      "Epoch: 58 loss: 0.5163 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n",
      "Epoch: 59 loss: 0.5160 Train_acc: 0.4333\n",
      "Epoch: 60 loss: 0.5157 Train_acc: 0.4333\n",
      "Test_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "num_epochs = 60\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_hat = model(x_1e, Linv, adjacency)\n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "        y_hat[: len(y_train)].float(), y_train.float()\n",
    "    )\n",
    "    epoch_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    y_pred = torch.where(y_hat > 0.5, torch.tensor(1), torch.tensor(0))\n",
    "    accuracy = (y_pred[-len(y_train) :] == y_train).all(dim=1).float().mean().item()\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {accuracy:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            y_hat_test = model(x_1e, Linv, adjacency)\n",
    "            y_pred_test = torch.where(\n",
    "                y_hat_test > 0.5, torch.tensor(1), torch.tensor(0)\n",
    "            )\n",
    "            test_accuracy = (\n",
    "                torch.eq(y_pred_test[-len(y_test) :], y_test)\n",
    "                .all(dim=1)\n",
    "                .float()\n",
    "                .mean()\n",
    "                .item()\n",
    "            )\n",
    "            print(f\"Test_acc: {test_accuracy:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
